# 机器学习(五)：通俗易懂决策树与随机森林

与SVM一样，决策树是通用的机器学习算法。随机森林，顾名思义，将决策树分类器集成到一起就形成了更强大的机器学习算法。它们都是很基础但很强大的机器学习工具，虽然我们现在有更先进的算法工具来训练模型，但决策树与随机森林因其简单灵活依然广受喜爱。



## 一、决策树

### 1.1 什么是决策树

我们可以把决策树想象成IF/ELSE判别式深度嵌套的二叉树形结构。以鸢尾花数据集为例。

用`seaborn`绘制花瓣长度和宽度特征对应鸢尾花种类的散点图，如下：

![image-20210327211224810](https://i.loli.net/2021/03/27/ezKfDvwqyBSu3pQ.png)

当花瓣长度小于2.45则为山鸢尾(setosa)，剩下的我们判断花瓣宽度小于1.75则为变色鸢尾(versicolor)剩下的为维吉尼亚鸢尾(virginica)。那么我用导图画一下这种判别式的树形结构如下：

![image-20210327211259574](https://i.loli.net/2021/03/27/xp31C57nMwjADYU.png)

因此，当我们面对任意鸢尾花的样本，我们只需要**从根节点到叶子节点遍历决策树**，就可以得到鸢尾花的分类结论。

这就是决策树。

### 1.2 决策树可视化

![image-20210327211351268](https://i.loli.net/2021/03/27/28iwvApGnNaCZTM.png)

可以看到根节点总实例数为150时，由`value = [50, 50, 50]`可知，实际样本分类为50个山鸢尾花实例、50个变色鸢尾花实例、50个维吉尼亚鸢尾花实例。我们再看最末尾右侧的叶子节点（紫色），由`value = [0, 1, 45]`可知，实际样本分类为0个山鸢尾花实例、1个变色鸢尾花实例、45个维吉尼亚鸢尾花实例。

那么gini = 0.043是什么意思呢？

### 1.3 基尼不纯度

显然我们进行分类时，每一个类别实际混入其他类的数量越少分类就越**纯粹**，这种纯度我们通过如下公式表示：

![image-20210327211503130](https://i.loli.net/2021/03/27/d6fTFGH93SxXRkn.png)

我们计算维吉尼亚鸢尾花节点（紫色）的gini系数`1-((0/46)**2 + (1/46)**2 + (45/46)**2) = 0.04253308128544431 ≈0.043` 。

我们使用基尼(gini)不纯度来衡量决策树的好坏。那么我们通过最小化基尼不纯度min(gini)来求解X[0],X[1]（即，花瓣长度宽度特征）边界的过程就决策树模型的训练过程。



## 二、随机森林

### 2.1 大数定理与随机森林

其实随机森林很简单，我们把决策树随机组合在一起就是随机森林，它比单个的决策树更有效。

凭什么？

假设我们有一枚不均匀的硬币，投掷它有51%的概率为正面，49%的概率为背面，那么当投掷1000次时，“大多数为正面"这件事的概率为75%。投掷10000次时，“大多数为正面"这件事的概率为97%。这就是大数定理，它体现的是群体智慧。*质量不够，数量来凑*。由此可知，当前寻找最佳模型的方法不止是技巧的比拼，也同样是算力的比拼。



## 总结

二叉树是决策树的核心逻辑，随机森林是大数定理的应用实现。这种基本思想即使不用数学公式也可以很容易的解释清楚。数学是对现实世界的解释，但现实世界并不能被数学**完全解释**。像谷歌AI主管Laurence Moroney所说：

> 很多人害怕数学，害怕大量的深度的微积分知识。其实我们可以实现编码而不考虑数学，我们可以使用TensorFlow中高(层)级的API，来解决问题，如自然语言处理，图像分类，计算机视觉序列模型等而无需理解深刻的数学。就像你使用JAVA却不一定非要掌握它是如何编译的。未来，AI只是每个开发者技术栈(toolbox)中的一部分，就像HTML, CSS, JAVA。

希望那一天可以早点到来吧……