{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - Decision Tree - III\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.导入数据\n",
    "\n",
    "#### 2.处理连续特征值（年龄，船票，家庭人数）\n",
    "\n",
    "#### 3.模型，预测可评估\n",
    "\n",
    "#### 4.超参数调整（优化模型），训练模型，取出各项指标最精确的模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lab02的缺点：\n",
    "#### 没有考虑连续值，只考率分类特征\n",
    "#### 只用了众数进行填充缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data analysis and preparing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采集数据\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_merged.csv')\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备和清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in combine:\n",
    "    df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "for df in combine:\n",
    "    df.drop(columns=['Ticket', 'PassengerId'], inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode(dropna=True)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把特征值的字符串类型变成整型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_encode = {\n",
    "    'Sex': {'male': 0, \"female\": 1},\n",
    "    'Embarked': {'S': 0, 'Q': 1, 'C': 2 }\n",
    "}\n",
    "\n",
    "for df in combine:\n",
    "    df.replace(num_encode, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.处理连续特征值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用age作为特征列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 填充缺失值 \n",
    "\n",
    "\n",
    "猜测缺失值的更准确方法是使用其他相关功能。在我们的案例中，我们注意到年龄，性别和Pclass之间的相关性。使用Pclass和Gender功能组合集的Age的中值来猜测Age值。因此，Pclass = 1和Gender = 0，Pclass = 1和Gender = 1的年龄中位数，依此类推...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺失值的填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x214911d5910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 514.88x475.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', height=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备一个空数组，以包含基于Pclass x Gender组合的年龄猜测值。使用船舱等级和性别作为数据集，放到数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历Sex（0或1）和Pclass（1、2、3）以计算这六个组合的Age猜测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "            age_guess = guess_df.median()\n",
    "            \n",
    "            guess_ages[i,j] = int(age_guess)\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            mask = dataset[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1)]     \n",
    "            if mask.empty:\n",
    "                continue\n",
    "            \n",
    "            dataset.loc[mask.index , 'Age'] = int(guess_ages[i, j])    \n",
    "                \n",
    "    # dataset.loc[:, 'Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    int64  \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Fare      891 non-null    float64\n",
      " 8   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将连续特征转换为分类特征，以在模型中使用它。创建年龄段并确定与生存的相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toddler/baby</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Child</td>\n",
       "      <td>0.516854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elderly</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AgeBand  Survived\n",
       "0  Toddler/baby  0.625000\n",
       "1         Child  0.516854\n",
       "2         Adult  0.363636\n",
       "3       Elderly  0.125000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'],bins=[0,2,17,65,99], labels=['Toddler/baby','Child','Adult','Elderly'])\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 在这里年龄可以直接分成4类并且有对应的年龄段，所以使用cut方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将四类年龄分别变成数值0，1，2，3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age AgeBand  SibSp  Parch     Fare  Embarked  \n",
       "0  22.0       2      1      0   7.2500         0  \n",
       "1  38.0       2      1      0  71.2833         2  \n",
       "2  26.0       2      0      0   7.9250         0  \n",
       "3  35.0       2      1      0  53.1000         0  \n",
       "4  35.0       2      0      0   8.0500         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop('AgeBand', inplace=True, axis=1)\n",
    "for df in combine:\n",
    "    category = pd.cut(df.Age,bins=[0,2,17,65,99], labels=[0, 1, 2, 3])\n",
    "    df.insert(5,'AgeBand', category)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 使用票价作为特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21491bab760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Survived', y='Fare', data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通过上图可以得知，与那些没有幸存的人相比，幸存的人们平均支付了更多的车费。\n",
    "\n",
    "通过为所有缺失值分配最频繁的票价来完善此功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   Survived  891 non-null    int64   \n",
      " 1   Pclass    891 non-null    int64   \n",
      " 2   Name      891 non-null    object  \n",
      " 3   Sex       891 non-null    int64   \n",
      " 4   Age       891 non-null    float64 \n",
      " 5   AgeBand   891 non-null    category\n",
      " 6   SibSp     891 non-null    int64   \n",
      " 7   Parch     891 non-null    int64   \n",
      " 8   Fare      891 non-null    float64 \n",
      " 9   Embarked  891 non-null    int64   \n",
      "dtypes: category(1), float64(2), int64(6), object(1)\n",
      "memory usage: 63.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Fare'].fillna(dataset['Fare'].mode(dropna=True)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.25\n",
      "71.2833\n",
      "7.925\n",
      "53.1\n",
      "8.05\n",
      "8.4583\n",
      "51.8625\n",
      "21.075\n",
      "11.1333\n",
      "30.0708\n",
      "16.7\n",
      "26.55\n",
      "8.05\n",
      "31.275\n",
      "7.8542\n",
      "16.0\n",
      "29.125\n",
      "13.0\n",
      "18.0\n",
      "7.225\n",
      "26.0\n",
      "13.0\n",
      "8.0292\n",
      "35.5\n",
      "21.075\n",
      "31.3875\n",
      "7.225\n",
      "263.0\n",
      "7.8792\n",
      "7.8958\n",
      "27.7208\n",
      "146.5208\n",
      "7.75\n",
      "10.5\n",
      "82.1708\n",
      "52.0\n",
      "7.2292\n",
      "8.05\n",
      "18.0\n",
      "11.2417\n",
      "9.475\n",
      "21.0\n",
      "7.8958\n",
      "41.5792\n",
      "7.8792\n",
      "8.05\n",
      "15.5\n",
      "7.75\n",
      "21.6792\n",
      "17.8\n",
      "39.6875\n",
      "7.8\n",
      "76.7292\n",
      "26.0\n",
      "61.9792\n",
      "35.5\n",
      "10.5\n",
      "7.2292\n",
      "27.75\n",
      "46.9\n",
      "7.2292\n",
      "80.0\n",
      "83.475\n",
      "27.9\n",
      "27.7208\n",
      "15.2458\n",
      "10.5\n",
      "8.1583\n",
      "7.925\n",
      "8.6625\n",
      "10.5\n",
      "46.9\n",
      "73.5\n",
      "14.4542\n",
      "56.4958\n",
      "7.65\n",
      "7.8958\n",
      "8.05\n",
      "29.0\n",
      "12.475\n",
      "9.0\n",
      "9.5\n",
      "7.7875\n",
      "47.1\n",
      "10.5\n",
      "15.85\n",
      "34.375\n",
      "8.05\n",
      "263.0\n",
      "8.05\n",
      "8.05\n",
      "7.8542\n",
      "61.175\n",
      "20.575\n",
      "7.25\n",
      "8.05\n",
      "34.6542\n",
      "63.3583\n",
      "23.0\n",
      "26.0\n",
      "7.8958\n",
      "7.8958\n",
      "77.2875\n",
      "8.6542\n",
      "7.925\n",
      "7.8958\n",
      "7.65\n",
      "7.775\n",
      "7.8958\n",
      "24.15\n",
      "52.0\n",
      "14.4542\n",
      "8.05\n",
      "9.825\n",
      "14.4583\n",
      "7.925\n",
      "7.75\n",
      "21.0\n",
      "247.5208\n",
      "31.275\n",
      "73.5\n",
      "8.05\n",
      "30.0708\n",
      "13.0\n",
      "77.2875\n",
      "11.2417\n",
      "7.75\n",
      "7.1417\n",
      "22.3583\n",
      "6.975\n",
      "7.8958\n",
      "7.05\n",
      "14.5\n",
      "26.0\n",
      "13.0\n",
      "15.0458\n",
      "26.2833\n",
      "53.1\n",
      "9.2167\n",
      "79.2\n",
      "15.2458\n",
      "7.75\n",
      "15.85\n",
      "6.75\n",
      "11.5\n",
      "36.75\n",
      "7.7958\n",
      "34.375\n",
      "26.0\n",
      "13.0\n",
      "12.525\n",
      "66.6\n",
      "8.05\n",
      "14.5\n",
      "7.3125\n",
      "61.3792\n",
      "7.7333\n",
      "8.05\n",
      "8.6625\n",
      "69.55\n",
      "16.1\n",
      "15.75\n",
      "7.775\n",
      "8.6625\n",
      "39.6875\n",
      "20.525\n",
      "55.0\n",
      "27.9\n",
      "25.925\n",
      "56.4958\n",
      "33.5\n",
      "29.125\n",
      "11.1333\n",
      "7.925\n",
      "30.6958\n",
      "7.8542\n",
      "25.4667\n",
      "28.7125\n",
      "13.0\n",
      "0.0\n",
      "69.55\n",
      "15.05\n",
      "31.3875\n",
      "39.0\n",
      "22.025\n",
      "50.0\n",
      "15.5\n",
      "26.55\n",
      "15.5\n",
      "7.8958\n",
      "13.0\n",
      "13.0\n",
      "7.8542\n",
      "26.0\n",
      "27.7208\n",
      "146.5208\n",
      "7.75\n",
      "8.4042\n",
      "7.75\n",
      "13.0\n",
      "9.5\n",
      "69.55\n",
      "6.4958\n",
      "7.225\n",
      "8.05\n",
      "10.4625\n",
      "15.85\n",
      "18.7875\n",
      "7.75\n",
      "31.0\n",
      "7.05\n",
      "21.0\n",
      "7.25\n",
      "13.0\n",
      "7.75\n",
      "113.275\n",
      "7.925\n",
      "27.0\n",
      "76.2917\n",
      "10.5\n",
      "8.05\n",
      "13.0\n",
      "8.05\n",
      "7.8958\n",
      "90.0\n",
      "9.35\n",
      "10.5\n",
      "7.25\n",
      "13.0\n",
      "25.4667\n",
      "83.475\n",
      "7.775\n",
      "13.5\n",
      "31.3875\n",
      "10.5\n",
      "7.55\n",
      "26.0\n",
      "26.25\n",
      "10.5\n",
      "12.275\n",
      "14.4542\n",
      "15.5\n",
      "10.5\n",
      "7.125\n",
      "7.225\n",
      "90.0\n",
      "7.775\n",
      "14.5\n",
      "52.5542\n",
      "26.0\n",
      "7.25\n",
      "10.4625\n",
      "26.55\n",
      "16.1\n",
      "20.2125\n",
      "15.2458\n",
      "79.2\n",
      "86.5\n",
      "512.3292\n",
      "26.0\n",
      "7.75\n",
      "31.3875\n",
      "79.65\n",
      "0.0\n",
      "7.75\n",
      "10.5\n",
      "39.6875\n",
      "7.775\n",
      "153.4625\n",
      "135.6333\n",
      "31.0\n",
      "0.0\n",
      "19.5\n",
      "29.7\n",
      "7.75\n",
      "77.9583\n",
      "7.75\n",
      "0.0\n",
      "29.125\n",
      "20.25\n",
      "7.75\n",
      "7.8542\n",
      "9.5\n",
      "8.05\n",
      "26.0\n",
      "8.6625\n",
      "9.5\n",
      "7.8958\n",
      "13.0\n",
      "7.75\n",
      "78.85\n",
      "91.0792\n",
      "12.875\n",
      "8.85\n",
      "7.8958\n",
      "27.7208\n",
      "7.2292\n",
      "151.55\n",
      "30.5\n",
      "247.5208\n",
      "7.75\n",
      "23.25\n",
      "0.0\n",
      "12.35\n",
      "8.05\n",
      "151.55\n",
      "110.8833\n",
      "108.9\n",
      "24.0\n",
      "56.9292\n",
      "83.1583\n",
      "262.375\n",
      "26.0\n",
      "7.8958\n",
      "26.25\n",
      "7.8542\n",
      "26.0\n",
      "14.0\n",
      "164.8667\n",
      "134.5\n",
      "7.25\n",
      "7.8958\n",
      "12.35\n",
      "29.0\n",
      "69.55\n",
      "135.6333\n",
      "6.2375\n",
      "13.0\n",
      "20.525\n",
      "57.9792\n",
      "23.25\n",
      "28.5\n",
      "153.4625\n",
      "18.0\n",
      "133.65\n",
      "7.8958\n",
      "66.6\n",
      "134.5\n",
      "8.05\n",
      "35.5\n",
      "26.0\n",
      "263.0\n",
      "13.0\n",
      "13.0\n",
      "13.0\n",
      "13.0\n",
      "13.0\n",
      "16.1\n",
      "15.9\n",
      "8.6625\n",
      "9.225\n",
      "35.0\n",
      "7.2292\n",
      "17.8\n",
      "7.225\n",
      "9.5\n",
      "55.0\n",
      "13.0\n",
      "7.8792\n",
      "7.8792\n",
      "27.9\n",
      "27.7208\n",
      "14.4542\n",
      "7.05\n",
      "15.5\n",
      "7.25\n",
      "75.25\n",
      "7.2292\n",
      "7.75\n",
      "69.3\n",
      "55.4417\n",
      "6.4958\n",
      "8.05\n",
      "135.6333\n",
      "21.075\n",
      "82.1708\n",
      "7.25\n",
      "211.5\n",
      "4.0125\n",
      "7.775\n",
      "227.525\n",
      "15.7417\n",
      "7.925\n",
      "52.0\n",
      "7.8958\n",
      "73.5\n",
      "46.9\n",
      "13.0\n",
      "7.7292\n",
      "12.0\n",
      "120.0\n",
      "7.7958\n",
      "7.925\n",
      "113.275\n",
      "16.7\n",
      "7.7958\n",
      "7.8542\n",
      "26.0\n",
      "10.5\n",
      "12.65\n",
      "7.925\n",
      "8.05\n",
      "9.825\n",
      "15.85\n",
      "8.6625\n",
      "21.0\n",
      "7.75\n",
      "18.75\n",
      "7.775\n",
      "25.4667\n",
      "7.8958\n",
      "6.8583\n",
      "90.0\n",
      "0.0\n",
      "7.925\n",
      "8.05\n",
      "32.5\n",
      "13.0\n",
      "13.0\n",
      "24.15\n",
      "7.8958\n",
      "7.7333\n",
      "7.875\n",
      "14.4\n",
      "20.2125\n",
      "7.25\n",
      "26.0\n",
      "26.0\n",
      "7.75\n",
      "8.05\n",
      "26.55\n",
      "16.1\n",
      "26.0\n",
      "7.125\n",
      "55.9\n",
      "120.0\n",
      "34.375\n",
      "18.75\n",
      "263.0\n",
      "10.5\n",
      "26.25\n",
      "9.5\n",
      "7.775\n",
      "13.0\n",
      "8.1125\n",
      "81.8583\n",
      "19.5\n",
      "26.55\n",
      "19.2583\n",
      "30.5\n",
      "27.75\n",
      "19.9667\n",
      "27.75\n",
      "89.1042\n",
      "8.05\n",
      "7.8958\n",
      "26.55\n",
      "51.8625\n",
      "10.5\n",
      "7.75\n",
      "26.55\n",
      "8.05\n",
      "38.5\n",
      "13.0\n",
      "8.05\n",
      "7.05\n",
      "0.0\n",
      "26.55\n",
      "7.725\n",
      "19.2583\n",
      "7.25\n",
      "8.6625\n",
      "27.75\n",
      "13.7917\n",
      "9.8375\n",
      "52.0\n",
      "21.0\n",
      "7.0458\n",
      "7.5208\n",
      "12.2875\n",
      "46.9\n",
      "0.0\n",
      "8.05\n",
      "9.5875\n",
      "91.0792\n",
      "25.4667\n",
      "90.0\n",
      "29.7\n",
      "8.05\n",
      "15.9\n",
      "19.9667\n",
      "7.25\n",
      "30.5\n",
      "49.5042\n",
      "8.05\n",
      "14.4583\n",
      "78.2667\n",
      "15.1\n",
      "151.55\n",
      "7.7958\n",
      "8.6625\n",
      "7.75\n",
      "7.6292\n",
      "9.5875\n",
      "86.5\n",
      "108.9\n",
      "26.0\n",
      "26.55\n",
      "22.525\n",
      "56.4958\n",
      "7.75\n",
      "8.05\n",
      "26.2875\n",
      "59.4\n",
      "7.4958\n",
      "34.0208\n",
      "10.5\n",
      "24.15\n",
      "26.0\n",
      "7.8958\n",
      "93.5\n",
      "7.8958\n",
      "7.225\n",
      "57.9792\n",
      "7.2292\n",
      "7.75\n",
      "10.5\n",
      "221.7792\n",
      "7.925\n",
      "11.5\n",
      "26.0\n",
      "7.2292\n",
      "7.2292\n",
      "22.3583\n",
      "8.6625\n",
      "26.25\n",
      "26.55\n",
      "106.425\n",
      "14.5\n",
      "49.5\n",
      "71.0\n",
      "31.275\n",
      "31.275\n",
      "26.0\n",
      "106.425\n",
      "26.0\n",
      "26.0\n",
      "13.8625\n",
      "20.525\n",
      "36.75\n",
      "110.8833\n",
      "26.0\n",
      "7.8292\n",
      "7.225\n",
      "7.775\n",
      "26.55\n",
      "39.6\n",
      "227.525\n",
      "79.65\n",
      "17.4\n",
      "7.75\n",
      "7.8958\n",
      "13.5\n",
      "8.05\n",
      "8.05\n",
      "24.15\n",
      "7.8958\n",
      "21.075\n",
      "7.2292\n",
      "7.8542\n",
      "10.5\n",
      "51.4792\n",
      "26.3875\n",
      "7.75\n",
      "8.05\n",
      "14.5\n",
      "13.0\n",
      "55.9\n",
      "14.4583\n",
      "7.925\n",
      "30.0\n",
      "110.8833\n",
      "26.0\n",
      "40.125\n",
      "8.7125\n",
      "79.65\n",
      "15.0\n",
      "79.2\n",
      "8.05\n",
      "8.05\n",
      "7.125\n",
      "78.2667\n",
      "7.25\n",
      "7.75\n",
      "26.0\n",
      "24.15\n",
      "33.0\n",
      "0.0\n",
      "7.225\n",
      "56.9292\n",
      "27.0\n",
      "7.8958\n",
      "42.4\n",
      "8.05\n",
      "26.55\n",
      "15.55\n",
      "7.8958\n",
      "30.5\n",
      "41.5792\n",
      "153.4625\n",
      "31.275\n",
      "7.05\n",
      "15.5\n",
      "7.75\n",
      "8.05\n",
      "65.0\n",
      "14.4\n",
      "16.1\n",
      "39.0\n",
      "10.5\n",
      "14.4542\n",
      "52.5542\n",
      "15.7417\n",
      "7.8542\n",
      "16.1\n",
      "32.3208\n",
      "12.35\n",
      "77.9583\n",
      "7.8958\n",
      "7.7333\n",
      "30.0\n",
      "7.0542\n",
      "30.5\n",
      "0.0\n",
      "27.9\n",
      "13.0\n",
      "7.925\n",
      "26.25\n",
      "39.6875\n",
      "16.1\n",
      "7.8542\n",
      "69.3\n",
      "27.9\n",
      "56.4958\n",
      "19.2583\n",
      "76.7292\n",
      "7.8958\n",
      "35.5\n",
      "7.55\n",
      "7.55\n",
      "7.8958\n",
      "23.0\n",
      "8.4333\n",
      "7.8292\n",
      "6.75\n",
      "73.5\n",
      "7.8958\n",
      "15.5\n",
      "13.0\n",
      "113.275\n",
      "133.65\n",
      "7.225\n",
      "25.5875\n",
      "7.4958\n",
      "7.925\n",
      "73.5\n",
      "13.0\n",
      "7.775\n",
      "8.05\n",
      "52.0\n",
      "39.0\n",
      "52.0\n",
      "10.5\n",
      "13.0\n",
      "0.0\n",
      "7.775\n",
      "8.05\n",
      "9.8417\n",
      "46.9\n",
      "512.3292\n",
      "8.1375\n",
      "76.7292\n",
      "9.225\n",
      "46.9\n",
      "39.0\n",
      "41.5792\n",
      "39.6875\n",
      "10.1708\n",
      "7.7958\n",
      "211.3375\n",
      "57.0\n",
      "13.4167\n",
      "56.4958\n",
      "7.225\n",
      "26.55\n",
      "13.5\n",
      "8.05\n",
      "7.7333\n",
      "110.8833\n",
      "7.65\n",
      "227.525\n",
      "26.2875\n",
      "14.4542\n",
      "7.7417\n",
      "7.8542\n",
      "26.0\n",
      "13.5\n",
      "26.2875\n",
      "151.55\n",
      "15.2458\n",
      "49.5042\n",
      "26.55\n",
      "52.0\n",
      "9.4833\n",
      "13.0\n",
      "7.65\n",
      "227.525\n",
      "10.5\n",
      "15.5\n",
      "7.775\n",
      "33.0\n",
      "7.0542\n",
      "13.0\n",
      "13.0\n",
      "53.1\n",
      "8.6625\n",
      "21.0\n",
      "7.7375\n",
      "26.0\n",
      "7.925\n",
      "211.3375\n",
      "18.7875\n",
      "0.0\n",
      "13.0\n",
      "13.0\n",
      "16.1\n",
      "34.375\n",
      "512.3292\n",
      "7.8958\n",
      "7.8958\n",
      "30.0\n",
      "78.85\n",
      "262.375\n",
      "16.1\n",
      "7.925\n",
      "71.0\n",
      "20.25\n",
      "13.0\n",
      "53.1\n",
      "7.75\n",
      "23.0\n",
      "12.475\n",
      "9.5\n",
      "7.8958\n",
      "65.0\n",
      "14.5\n",
      "7.7958\n",
      "11.5\n",
      "8.05\n",
      "86.5\n",
      "14.5\n",
      "7.125\n",
      "7.2292\n",
      "120.0\n",
      "7.775\n",
      "77.9583\n",
      "39.6\n",
      "7.75\n",
      "24.15\n",
      "8.3625\n",
      "9.5\n",
      "7.8542\n",
      "10.5\n",
      "7.225\n",
      "23.0\n",
      "7.75\n",
      "7.75\n",
      "12.475\n",
      "7.7375\n",
      "211.3375\n",
      "7.2292\n",
      "57.0\n",
      "30.0\n",
      "23.45\n",
      "7.05\n",
      "7.25\n",
      "7.4958\n",
      "29.125\n",
      "20.575\n",
      "79.2\n",
      "7.75\n",
      "26.0\n",
      "69.55\n",
      "30.6958\n",
      "7.8958\n",
      "13.0\n",
      "25.9292\n",
      "8.6833\n",
      "7.2292\n",
      "24.15\n",
      "13.0\n",
      "26.25\n",
      "120.0\n",
      "8.5167\n",
      "6.975\n",
      "7.775\n",
      "0.0\n",
      "7.775\n",
      "13.0\n",
      "53.1\n",
      "7.8875\n",
      "24.15\n",
      "10.5\n",
      "31.275\n",
      "8.05\n",
      "0.0\n",
      "7.925\n",
      "37.0042\n",
      "6.45\n",
      "27.9\n",
      "93.5\n",
      "8.6625\n",
      "0.0\n",
      "12.475\n",
      "39.6875\n",
      "6.95\n",
      "56.4958\n",
      "37.0042\n",
      "7.75\n",
      "80.0\n",
      "14.4542\n",
      "18.75\n",
      "7.2292\n",
      "7.8542\n",
      "8.3\n",
      "83.1583\n",
      "8.6625\n",
      "8.05\n",
      "56.4958\n",
      "29.7\n",
      "7.925\n",
      "10.5\n",
      "31.0\n",
      "6.4375\n",
      "8.6625\n",
      "7.55\n",
      "69.55\n",
      "7.8958\n",
      "33.0\n",
      "89.1042\n",
      "31.275\n",
      "7.775\n",
      "15.2458\n",
      "39.4\n",
      "26.0\n",
      "9.35\n",
      "164.8667\n",
      "26.55\n",
      "19.2583\n",
      "7.2292\n",
      "14.1083\n",
      "11.5\n",
      "25.9292\n",
      "69.55\n",
      "13.0\n",
      "13.0\n",
      "13.8583\n",
      "50.4958\n",
      "9.5\n",
      "11.1333\n",
      "7.8958\n",
      "52.5542\n",
      "5.0\n",
      "9.0\n",
      "24.0\n",
      "7.225\n",
      "9.8458\n",
      "7.8958\n",
      "7.8958\n",
      "83.1583\n",
      "26.0\n",
      "7.8958\n",
      "10.5167\n",
      "10.5\n",
      "7.05\n",
      "29.125\n",
      "13.0\n",
      "30.0\n",
      "23.45\n",
      "30.0\n",
      "7.75\n"
     ]
    }
   ],
   "source": [
    "for d in train_df['Fare']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用四分位值创建票价区。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qcut 保证每个组里的元素个数是相等的\n",
    "#### 通过上述数据显示，规律性不强，所以直接使用qcut方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FareBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>0.197309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>0.454955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>0.581081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FareBand  Survived\n",
       "0   (-0.001, 7.91]  0.197309\n",
       "1   (7.91, 14.454]  0.303571\n",
       "2   (14.454, 31.0]  0.454955\n",
       "3  (31.0, 512.329]  0.581081"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'],[0, 0.25, 0.5, 0.75, 1])\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "FareBand可以直观的显示出存活率。这样就变成了一个序数特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked  \n",
       "0  22.0        0       2      1      0   7.2500         0  \n",
       "1  38.0        3       2      1      0  71.2833         2  \n",
       "2  26.0        1       2      0      0   7.9250         0  \n",
       "3  35.0        3       2      1      0  53.1000         0  \n",
       "4  35.0        1       2      0      0   8.0500         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(['FareBand'], axis=1, inplace=True)\n",
    "for df in combine:\n",
    "    category = pd.qcut(df.Fare, q=4, labels=[0, 1, 2, 3])\n",
    "    df.insert(5,'FareBand', category)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 创建从现有特征中提取的新特征\n",
    "\n",
    "#### 使用正则表达式截取人名的最开始部分，作为身份特征列，观察与生存率之间的关系\n",
    "\n",
    "使用正则表达式提取人名最开始部分。RegEx模式(\\w+\\.)与名称功能中第一个以点字符结尾的单词匹配。expand=False标志返回一个DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AgeBand</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>488</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AgeBand    0   1    2  3\n",
       "Title                   \n",
       "Capt       0   0    0  1\n",
       "Col        0   0    2  0\n",
       "Countess   0   0    1  0\n",
       "Don        0   0    1  0\n",
       "Dr         0   0    7  0\n",
       "Jonkheer   0   0    1  0\n",
       "Lady       0   0    1  0\n",
       "Major      0   0    2  0\n",
       "Master    14  22    4  0\n",
       "Miss      10  41  131  0\n",
       "Mlle       0   0    2  0\n",
       "Mme        0   0    1  0\n",
       "Mr         0  22  488  7\n",
       "Mrs        0   4  121  0\n",
       "Ms         0   0    1  0\n",
       "Rev        0   0    6  0\n",
       "Sir        0   0    1  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Title'] = train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(train_df['Title'], train_df['AgeBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>55</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "Capt        1    0\n",
       "Col         1    1\n",
       "Countess    0    1\n",
       "Don         1    0\n",
       "Dr          4    3\n",
       "Jonkheer    1    0\n",
       "Lady        0    1\n",
       "Major       1    1\n",
       "Master     17   23\n",
       "Miss       55  127\n",
       "Mlle        0    2\n",
       "Mme         0    1\n",
       "Mr        436   81\n",
       "Mrs        26   99\n",
       "Ms          0    1\n",
       "Rev         6    0\n",
       "Sir         0    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_df['Title'], train_df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通过上面的dataframe，可以得到：\n",
    "\n",
    "#### 1.截取出来的字段大多数会准确区分年龄段。例如：Master 字段 年龄是小于17岁的\n",
    "#### 2.这些字段对应的存活率略有不同\n",
    "#### 3.某些字段（Mme，Lady，Sir）幸存率很高，而（Don，Rev，Jonkheer）这些字段幸存率很低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Title'], axis=1, inplace=True)\n",
    "for df in combine:\n",
    "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "对这些字段进行操作，将名字分成几类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked Title  \n",
       "0  22.0        0       2      1      0   7.2500         0    Mr  \n",
       "1  38.0        3       2      1      0  71.2833         2   Mrs  \n",
       "2  26.0        1       2      0      0   7.9250         0  Miss  \n",
       "3  35.0        3       2      1      0  53.1000         0   Mrs  \n",
       "4  35.0        1       2      0      0   8.0500         0    Mr  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "将这些分类标题转换为序数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked  Title  \n",
       "0  22.0        0       2      1      0   7.2500         0      1  \n",
       "1  38.0        3       2      1      0  71.2833         2      3  \n",
       "2  26.0        1       2      0      0   7.9250         0      2  \n",
       "3  35.0        3       2      1      0  53.1000         0      3  \n",
       "4  35.0        1       2      0      0   8.0500         0      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据集中删除“名称”列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.drop('Name', inplace=True, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 来自SibSp和Parch的家庭人数\n",
    "在lab02中，'SibSp'和'Parch'并不是很好的列。因此，结合这些列，创建一个名为“ FamilySize”的新列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FamilySize  Survived\n",
       "3           4  0.724138\n",
       "2           3  0.578431\n",
       "1           2  0.552795\n",
       "6           7  0.333333\n",
       "0           1  0.303538\n",
       "4           5  0.200000\n",
       "5           6  0.136364\n",
       "7           8  0.000000\n",
       "8          11  0.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1    \n",
    "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图观察可以发现家庭成员为（4，3，2）的存活率最高，为（7，1，5，6）的存活率较低，为（8，11）的存活率最低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如上图所示，FamilySize但是它有几个类别。但是不好进行操作，现在创建一个称为IsAlone的新列，以最大程度地减少复杂性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(['FamilySize'], axis=1, inplace=True)\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md"
    }
   },
   "source": [
    "删除“FamilySize”这一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age FareBand AgeBand  SibSp  Parch     Fare  \\\n",
       "0         0       3    0  22.0        0       2      1      0   7.2500   \n",
       "1         1       1    1  38.0        3       2      1      0  71.2833   \n",
       "2         1       3    1  26.0        1       2      0      0   7.9250   \n",
       "3         1       1    1  35.0        3       2      1      0  53.1000   \n",
       "4         0       3    0  35.0        1       2      0      0   8.0500   \n",
       "\n",
       "   Embarked  Title  IsAlone  \n",
       "0         0      1        0  \n",
       "1         2      3        0  \n",
       "2         0      2        1  \n",
       "3         0      3        0  \n",
       "4         0      1        1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.drop(['FamilySize'], axis=1, inplace=True)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.模型，预测和评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "让我们根据数据进行训练，验证和测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值不能存在，需要将存活率得到列删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "X_test = test_df.drop('Survived', axis=1)\n",
    "y_test = test_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "combine = [X_train, X_valid, X_test] #训练集，验证集，测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "重新创建上周构建的决策树模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = X_train[['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']]\n",
    "X_valid_cat = X_valid[['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']]\n",
    "\n",
    "cat_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "#criterion:string类型，可选（默认为\"gini\"）\n",
    "#衡量分类的质量。支持的标准有\"gini\"代表的是Gini impurity(不纯度)与\"entropy\"代表的是information gain（信息增益）。\n",
    "\n",
    "cat_tree.fit(X_train_cat, y_train)\n",
    "y_pred = cat_tree.predict(X_valid_cat)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度：0.7985074626865671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_state=42  \n",
    "https://www.jianshu.com/p/4deb2cb2502f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier（）方法详解\n",
    "https://blog.csdn.net/li980828298/article/details/51172744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "预测生成混淆矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148  13]\n",
      " [ 41  66]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The index mapping of the above matrix is as follows,\n",
    "\n",
    "- [0, 0] - True Positive\n",
    "- [0, 1] - False Negative\n",
    "- [1, 0] - False Positive\n",
    "- [1, 1] - True Negative\n",
    "\n",
    "Let's generate the classification report of our predicted data. Classification report contains information such as \n",
    "accuracy and precision, recall and f1-score for each output class.\n",
    "You can get more information on classification report here: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过混淆矩阵：https://blog.csdn.net/u011734144/article/details/80277225\n",
    "#### 生成预测数据的分类报告。分类报告包含每个输出类别的信息，例如准确度和精确度，召回率和f1得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       161\n",
      "           1       0.84      0.62      0.71       107\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.81      0.77      0.78       268\n",
      "weighted avg       0.80      0.80      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       精度召回f1得分支持\n",
    "\n",
    "           0 0.78 0.92 0.85 161 \n",
    "           1 0.84 0.62 0.71 107\n",
    "\n",
    "    精度0.80 268\n",
    "   宏平均0.81 0.77 0.78 268\n",
    "\n",
    "加权平均0.80 0.80 0.79 268\n",
    "\n",
    "https://blog.csdn.net/qq_40765537/article/details/105344798?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 继续建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "添加策划的新列，并尝试训练新模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)\n",
    "X_test.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)\n",
    "X_valid.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       161\n",
      "           1       0.77      0.69      0.73       107\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.79      0.78      0.78       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "entropy_tree.fit(X_train, y_train)\n",
    "y_pred = entropy_tree.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "绘制该决策树。可以在sci_kit中使用plot_tree（）函数学习可视化建模的树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(194.93238106343284, 211.7178947368421, 'X[1] <= 0.5\\nentropy = 0.956\\nsamples = 623\\nvalue = [388, 235]'),\n",
       " Text(106.75263526119403, 200.2736842105263, 'X[3] <= 1.5\\nentropy = 0.696\\nsamples = 406\\nvalue = [330, 76]'),\n",
       " Text(47.94011194029851, 188.82947368421054, 'X[2] <= 14.0\\nentropy = 0.493\\nsamples = 232\\nvalue = [207, 25]'),\n",
       " Text(45.441604477611946, 177.38526315789474, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(50.438619402985076, 177.38526315789474, 'X[3] <= 0.5\\nentropy = 0.456\\nsamples = 229\\nvalue = [207, 22]'),\n",
       " Text(25.609701492537315, 165.94105263157894, 'X[2] <= 29.5\\nentropy = 0.321\\nsamples = 120\\nvalue = [113, 7]'),\n",
       " Text(23.111194029850747, 154.49684210526317, 'X[2] <= 20.5\\nentropy = 0.401\\nsamples = 88\\nvalue = [81, 7]'),\n",
       " Text(20.61268656716418, 143.05263157894737, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(25.609701492537315, 143.05263157894737, 'X[2] <= 26.5\\nentropy = 0.443\\nsamples = 76\\nvalue = [69, 7]'),\n",
       " Text(13.74179104477612, 131.60842105263157, 'X[7] <= 0.5\\nentropy = 0.383\\nsamples = 67\\nvalue = [62, 5]'),\n",
       " Text(4.997014925373135, 120.16421052631578, 'X[2] <= 23.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(2.4985074626865673, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(7.495522388059702, 108.72, 'X[5] <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(4.997014925373135, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(9.99402985074627, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(22.486567164179107, 120.16421052631578, 'X[2] <= 22.5\\nentropy = 0.337\\nsamples = 64\\nvalue = [60, 4]'),\n",
       " Text(17.48955223880597, 108.72, 'X[5] <= 1.0\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 2]'),\n",
       " Text(14.991044776119404, 97.27578947368421, 'X[2] <= 21.5\\nentropy = 0.469\\nsamples = 10\\nvalue = [9, 1]'),\n",
       " Text(12.492537313432837, 85.83157894736843, 'entropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(17.48955223880597, 85.83157894736843, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(19.98805970149254, 97.27578947368421, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(27.48358208955224, 108.72, 'X[2] <= 24.5\\nentropy = 0.235\\nsamples = 52\\nvalue = [50, 2]'),\n",
       " Text(24.985074626865675, 97.27578947368421, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(29.982089552238808, 97.27578947368421, 'X[5] <= 1.5\\nentropy = 0.254\\nsamples = 47\\nvalue = [45, 2]'),\n",
       " Text(27.48358208955224, 85.83157894736843, 'X[5] <= 0.5\\nentropy = 0.196\\nsamples = 33\\nvalue = [32, 1]'),\n",
       " Text(24.985074626865675, 74.38736842105263, 'X[2] <= 25.5\\nentropy = 0.297\\nsamples = 19\\nvalue = [18, 1]'),\n",
       " Text(22.486567164179107, 62.943157894736856, 'entropy = 0.337\\nsamples = 16\\nvalue = [15, 1]'),\n",
       " Text(27.48358208955224, 62.943157894736856, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(29.982089552238808, 74.38736842105263, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(32.48059701492537, 85.83157894736843, 'entropy = 0.371\\nsamples = 14\\nvalue = [13, 1]'),\n",
       " Text(37.47761194029851, 131.60842105263157, 'X[5] <= 1.0\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(34.97910447761194, 120.16421052631578, 'X[2] <= 27.5\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(32.48059701492537, 108.72, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(37.47761194029851, 108.72, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(39.97611940298508, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(28.108208955223883, 154.49684210526317, 'entropy = 0.0\\nsamples = 32\\nvalue = [32, 0]'),\n",
       " Text(75.26753731343284, 165.94105263157894, 'X[2] <= 29.5\\nentropy = 0.578\\nsamples = 109\\nvalue = [94, 15]'),\n",
       " Text(51.844029850746274, 154.49684210526317, 'X[0] <= 2.5\\nentropy = 0.345\\nsamples = 62\\nvalue = [58, 4]'),\n",
       " Text(49.345522388059706, 143.05263157894737, 'entropy = 0.0\\nsamples = 17\\nvalue = [17, 0]'),\n",
       " Text(54.34253731343284, 143.05263157894737, 'X[7] <= 0.5\\nentropy = 0.433\\nsamples = 45\\nvalue = [41, 4]'),\n",
       " Text(47.47164179104478, 131.60842105263157, 'X[2] <= 23.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(44.97313432835821, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(49.97014925373135, 120.16421052631578, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(61.213432835820896, 131.60842105263157, 'X[2] <= 26.5\\nentropy = 0.378\\nsamples = 41\\nvalue = [38, 3]'),\n",
       " Text(54.96716417910448, 120.16421052631578, 'X[2] <= 18.5\\nentropy = 0.31\\nsamples = 36\\nvalue = [34, 2]'),\n",
       " Text(49.97014925373135, 108.72, 'X[4] <= 1.5\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(47.47164179104478, 97.27578947368421, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(52.46865671641791, 97.27578947368421, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(59.964179104477616, 108.72, 'X[2] <= 24.75\\nentropy = 0.216\\nsamples = 29\\nvalue = [28, 1]'),\n",
       " Text(57.46567164179105, 97.27578947368421, 'entropy = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(62.462686567164184, 97.27578947368421, 'X[5] <= 0.5\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(59.964179104477616, 85.83157894736843, 'X[2] <= 25.5\\nentropy = 0.439\\nsamples = 11\\nvalue = [10, 1]'),\n",
       " Text(57.46567164179105, 74.38736842105263, 'entropy = 0.469\\nsamples = 10\\nvalue = [9, 1]'),\n",
       " Text(62.462686567164184, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(64.96119402985074, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(67.45970149253732, 120.16421052631578, 'X[2] <= 27.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(64.96119402985074, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(69.95820895522388, 108.72, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(98.69104477611941, 154.49684210526317, 'X[2] <= 32.5\\nentropy = 0.785\\nsamples = 47\\nvalue = [36, 11]'),\n",
       " Text(84.94925373134329, 143.05263157894737, 'X[5] <= 1.0\\nentropy = 1.0\\nsamples = 12\\nvalue = [6, 6]'),\n",
       " Text(82.45074626865672, 131.60842105263157, 'X[2] <= 30.75\\nentropy = 0.994\\nsamples = 11\\nvalue = [6, 5]'),\n",
       " Text(77.4537313432836, 120.16421052631578, 'X[0] <= 2.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(74.95522388059702, 108.72, 'entropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(79.95223880597015, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(87.44776119402985, 120.16421052631578, 'X[0] <= 2.5\\nentropy = 0.918\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(84.94925373134329, 108.72, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(89.94626865671643, 108.72, 'X[2] <= 31.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(87.44776119402985, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(92.44477611940299, 97.27578947368421, 'entropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(87.44776119402985, 131.60842105263157, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(112.43283582089553, 143.05263157894737, 'X[2] <= 60.5\\nentropy = 0.592\\nsamples = 35\\nvalue = [30, 5]'),\n",
       " Text(107.4358208955224, 131.60842105263157, 'X[2] <= 46.0\\nentropy = 0.533\\nsamples = 33\\nvalue = [29, 4]'),\n",
       " Text(104.93731343283582, 120.16421052631578, 'X[2] <= 43.5\\nentropy = 0.667\\nsamples = 23\\nvalue = [19, 4]'),\n",
       " Text(99.9402985074627, 108.72, 'X[2] <= 40.5\\nentropy = 0.469\\nsamples = 20\\nvalue = [18, 2]'),\n",
       " Text(97.44179104477612, 97.27578947368421, 'X[2] <= 38.5\\nentropy = 0.544\\nsamples = 16\\nvalue = [14, 2]'),\n",
       " Text(92.44477611940299, 85.83157894736843, 'X[0] <= 2.5\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(89.94626865671643, 74.38736842105263, 'X[2] <= 35.0\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(87.44776119402985, 62.943157894736856, 'X[2] <= 33.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(84.94925373134329, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(89.94626865671643, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(92.44477611940299, 62.943157894736856, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(94.94328358208956, 74.38736842105263, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(102.43880597014926, 85.83157894736843, 'X[0] <= 2.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(99.9402985074627, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(104.93731343283582, 74.38736842105263, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(102.43880597014926, 97.27578947368421, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(109.93432835820896, 108.72, 'X[2] <= 44.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(107.4358208955224, 97.27578947368421, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(112.43283582089553, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(109.93432835820896, 120.16421052631578, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(117.42985074626867, 131.60842105263157, 'X[2] <= 64.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(114.9313432835821, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(119.92835820895523, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(165.56515858208957, 188.82947368421054, 'X[2] <= 3.5\\nentropy = 0.873\\nsamples = 174\\nvalue = [123, 51]'),\n",
       " Text(141.00951492537314, 177.38526315789474, 'X[0] <= 2.5\\nentropy = 0.961\\nsamples = 13\\nvalue = [5, 8]'),\n",
       " Text(138.51100746268656, 165.94105263157894, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(143.50802238805971, 165.94105263157894, 'X[2] <= 2.5\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(141.00951492537314, 154.49684210526317, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(146.0065298507463, 154.49684210526317, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(190.120802238806, 177.38526315789474, 'X[0] <= 1.5\\nentropy = 0.837\\nsamples = 161\\nvalue = [118, 43]'),\n",
       " Text(153.502052238806, 165.94105263157894, 'X[2] <= 60.5\\nentropy = 0.949\\nsamples = 87\\nvalue = [55, 32]'),\n",
       " Text(151.0035447761194, 154.49684210526317, 'X[4] <= 1.5\\nentropy = 0.974\\nsamples = 79\\nvalue = [47, 32]'),\n",
       " Text(148.50503731343284, 143.05263157894737, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(153.502052238806, 143.05263157894737, 'X[2] <= 22.5\\nentropy = 0.965\\nsamples = 77\\nvalue = [47, 30]'),\n",
       " Text(151.0035447761194, 131.60842105263157, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(156.00055970149253, 131.60842105263157, 'X[2] <= 26.0\\nentropy = 0.977\\nsamples = 73\\nvalue = [43, 30]'),\n",
       " Text(153.502052238806, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(158.4990671641791, 120.16421052631578, 'X[2] <= 47.5\\nentropy = 0.968\\nsamples = 71\\nvalue = [43, 28]'),\n",
       " Text(137.1055970149254, 108.72, 'X[2] <= 45.25\\nentropy = 0.936\\nsamples = 54\\nvalue = [35, 19]'),\n",
       " Text(134.60708955223882, 97.27578947368421, 'X[3] <= 2.5\\nentropy = 0.968\\nsamples = 48\\nvalue = [29, 19]'),\n",
       " Text(114.9313432835821, 85.83157894736843, 'X[5] <= 1.0\\nentropy = 0.993\\nsamples = 20\\nvalue = [9, 11]'),\n",
       " Text(109.93432835820896, 74.38736842105263, 'X[6] <= 3.0\\nentropy = 0.863\\nsamples = 14\\nvalue = [4, 10]'),\n",
       " Text(107.4358208955224, 62.943157894736856, 'X[2] <= 28.5\\nentropy = 0.779\\nsamples = 13\\nvalue = [3, 10]'),\n",
       " Text(104.93731343283582, 51.49894736842106, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(109.93432835820896, 51.49894736842106, 'X[2] <= 31.5\\nentropy = 0.845\\nsamples = 11\\nvalue = [3, 8]'),\n",
       " Text(107.4358208955224, 40.05473684210526, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(112.43283582089553, 40.05473684210526, 'X[2] <= 38.0\\nentropy = 0.722\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(109.93432835820896, 28.610526315789485, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(114.9313432835821, 28.610526315789485, 'X[2] <= 41.0\\nentropy = 0.918\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(112.43283582089553, 17.166315789473686, 'entropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(117.42985074626867, 17.166315789473686, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(112.43283582089553, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(119.92835820895523, 74.38736842105263, 'X[2] <= 38.5\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(117.42985074626867, 62.943157894736856, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(122.42686567164179, 62.943157894736856, 'X[6] <= 3.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(119.92835820895523, 51.49894736842106, 'entropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(124.92537313432837, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(154.28283582089554, 85.83157894736843, 'X[2] <= 39.0\\nentropy = 0.863\\nsamples = 28\\nvalue = [20, 8]'),\n",
       " Text(143.66417910447763, 74.38736842105263, 'X[2] <= 33.0\\nentropy = 0.954\\nsamples = 16\\nvalue = [10, 6]'),\n",
       " Text(134.91940298507464, 62.943157894736856, 'X[2] <= 27.5\\nentropy = 0.811\\nsamples = 8\\nvalue = [6, 2]'),\n",
       " Text(129.9223880597015, 51.49894736842106, 'X[7] <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(127.42388059701493, 40.05473684210526, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(132.42089552238807, 40.05473684210526, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(139.91641791044776, 51.49894736842106, 'X[2] <= 30.0\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(137.41791044776122, 40.05473684210526, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(142.41492537313434, 40.05473684210526, 'X[7] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(139.91641791044776, 28.610526315789485, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(144.9134328358209, 28.610526315789485, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(152.4089552238806, 62.943157894736856, 'X[2] <= 35.5\\nentropy = 1.0\\nsamples = 8\\nvalue = [4, 4]'),\n",
       " Text(149.91044776119404, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(154.9074626865672, 51.49894736842106, 'X[7] <= 0.5\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(152.4089552238806, 40.05473684210526, 'X[5] <= 1.0\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(149.91044776119404, 28.610526315789485, 'X[2] <= 36.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(147.41194029850746, 17.166315789473686, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(152.4089552238806, 17.166315789473686, 'X[2] <= 37.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(149.91044776119404, 5.722105263157886, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(154.9074626865672, 5.722105263157886, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(154.9074626865672, 28.610526315789485, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(157.40597014925373, 40.05473684210526, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(164.90149253731343, 74.38736842105263, 'X[2] <= 43.5\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 2]'),\n",
       " Text(162.40298507462688, 62.943157894736856, 'X[7] <= 0.5\\nentropy = 0.722\\nsamples = 10\\nvalue = [8, 2]'),\n",
       " Text(159.9044776119403, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(164.90149253731343, 51.49894736842106, 'X[5] <= 1.0\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(162.40298507462688, 40.05473684210526, 'entropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(167.4, 40.05473684210526, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(167.4, 62.943157894736856, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(139.60410447761194, 97.27578947368421, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(179.89253731343285, 108.72, 'X[2] <= 49.5\\nentropy = 0.998\\nsamples = 17\\nvalue = [8, 9]'),\n",
       " Text(177.39402985074628, 97.27578947368421, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(182.3910447761194, 97.27578947368421, 'X[6] <= 3.0\\nentropy = 0.961\\nsamples = 13\\nvalue = [8, 5]'),\n",
       " Text(177.39402985074628, 85.83157894736843, 'X[2] <= 59.0\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(174.8955223880597, 74.38736842105263, 'X[2] <= 51.5\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(172.39701492537316, 62.943157894736856, 'X[7] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(169.89850746268658, 51.49894736842106, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(174.8955223880597, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(177.39402985074628, 62.943157894736856, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(179.89253731343285, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(187.38805970149255, 85.83157894736843, 'X[2] <= 58.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(184.88955223880598, 74.38736842105263, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(189.88656716417913, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(156.00055970149253, 154.49684210526317, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(226.73955223880597, 165.94105263157894, 'X[2] <= 32.25\\nentropy = 0.606\\nsamples = 74\\nvalue = [63, 11]'),\n",
       " Text(224.24104477611942, 154.49684210526317, 'X[2] <= 31.5\\nentropy = 0.694\\nsamples = 59\\nvalue = [48, 11]'),\n",
       " Text(216.12089552238808, 143.05263157894737, 'X[0] <= 2.5\\nentropy = 0.636\\nsamples = 56\\nvalue = [47, 9]'),\n",
       " Text(213.6223880597015, 131.60842105263157, 'entropy = 0.0\\nsamples = 13\\nvalue = [13, 0]'),\n",
       " Text(218.61940298507463, 131.60842105263157, 'X[5] <= 1.5\\nentropy = 0.74\\nsamples = 43\\nvalue = [34, 9]'),\n",
       " Text(209.87462686567164, 120.16421052631578, 'X[7] <= 0.5\\nentropy = 0.629\\nsamples = 38\\nvalue = [32, 6]'),\n",
       " Text(204.87761194029852, 108.72, 'X[3] <= 2.5\\nentropy = 0.491\\nsamples = 28\\nvalue = [25, 3]'),\n",
       " Text(202.37910447761195, 97.27578947368421, 'X[2] <= 9.5\\nentropy = 0.65\\nsamples = 18\\nvalue = [15, 3]'),\n",
       " Text(197.38208955223882, 85.83157894736843, 'X[2] <= 8.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(194.88358208955225, 74.38736842105263, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(199.8805970149254, 74.38736842105263, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(207.3761194029851, 85.83157894736843, 'X[5] <= 0.5\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(204.87761194029852, 74.38736842105263, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(209.87462686567164, 74.38736842105263, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(207.3761194029851, 97.27578947368421, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(214.8716417910448, 108.72, 'X[3] <= 2.5\\nentropy = 0.881\\nsamples = 10\\nvalue = [7, 3]'),\n",
       " Text(212.37313432835822, 97.27578947368421, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(217.37014925373137, 97.27578947368421, 'X[2] <= 27.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(214.8716417910448, 85.83157894736843, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(219.86865671641792, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(227.3641791044776, 120.16421052631578, 'X[4] <= 1.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(224.86567164179107, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(229.8626865671642, 108.72, 'X[7] <= 0.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(227.3641791044776, 97.27578947368421, 'X[2] <= 22.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(224.86567164179107, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(229.8626865671642, 85.83157894736843, 'X[6] <= 2.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(227.3641791044776, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(232.36119402985076, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(232.36119402985076, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(232.36119402985076, 143.05263157894737, 'X[3] <= 2.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(229.8626865671642, 131.60842105263157, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(234.85970149253734, 131.60842105263157, 'X[0] <= 2.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(232.36119402985076, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(237.3582089552239, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(229.23805970149255, 154.49684210526317, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(283.11212686567166, 200.2736842105263, 'X[0] <= 2.5\\nentropy = 0.838\\nsamples = 217\\nvalue = [58, 159]'),\n",
       " Text(262.34328358208955, 188.82947368421054, 'X[3] <= 2.5\\nentropy = 0.355\\nsamples = 119\\nvalue = [8, 111]'),\n",
       " Text(252.3492537313433, 177.38526315789474, 'X[2] <= 23.5\\nentropy = 0.51\\nsamples = 53\\nvalue = [6, 47]'),\n",
       " Text(249.85074626865674, 165.94105263157894, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13]'),\n",
       " Text(254.84776119402986, 165.94105263157894, 'X[2] <= 27.5\\nentropy = 0.61\\nsamples = 40\\nvalue = [6, 34]'),\n",
       " Text(247.35223880597016, 154.49684210526317, 'X[2] <= 25.5\\nentropy = 0.918\\nsamples = 9\\nvalue = [3, 6]'),\n",
       " Text(242.35522388059704, 143.05263157894737, 'X[7] <= 0.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(239.85671641791046, 131.60842105263157, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(244.85373134328358, 131.60842105263157, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(252.3492537313433, 143.05263157894737, 'X[6] <= 2.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(249.85074626865674, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(254.84776119402986, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(262.34328358208955, 154.49684210526317, 'X[2] <= 37.0\\nentropy = 0.459\\nsamples = 31\\nvalue = [3, 28]'),\n",
       " Text(259.844776119403, 143.05263157894737, 'entropy = 0.0\\nsamples = 17\\nvalue = [0, 17]'),\n",
       " Text(264.84179104477613, 143.05263157894737, 'X[6] <= 2.5\\nentropy = 0.75\\nsamples = 14\\nvalue = [3, 11]'),\n",
       " Text(259.844776119403, 131.60842105263157, 'X[5] <= 1.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(257.34626865671646, 120.16421052631578, 'X[2] <= 44.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(254.84776119402986, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(259.844776119403, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(262.34328358208955, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(269.8388059701493, 131.60842105263157, 'X[7] <= 0.5\\nentropy = 0.439\\nsamples = 11\\nvalue = [1, 10]'),\n",
       " Text(267.3402985074627, 120.16421052631578, 'X[2] <= 43.0\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(264.84179104477613, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(269.8388059701493, 108.72, 'X[2] <= 44.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(267.3402985074627, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(272.33731343283586, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(272.33731343283586, 120.16421052631578, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(272.33731343283586, 177.38526315789474, 'X[2] <= 2.5\\nentropy = 0.196\\nsamples = 66\\nvalue = [2, 64]'),\n",
       " Text(269.8388059701493, 165.94105263157894, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(274.83582089552243, 165.94105263157894, 'X[2] <= 25.5\\nentropy = 0.115\\nsamples = 65\\nvalue = [1, 64]'),\n",
       " Text(272.33731343283586, 154.49684210526317, 'X[2] <= 24.5\\nentropy = 0.276\\nsamples = 21\\nvalue = [1, 20]'),\n",
       " Text(269.8388059701493, 143.05263157894737, 'entropy = 0.0\\nsamples = 20\\nvalue = [0, 20]'),\n",
       " Text(274.83582089552243, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(277.33432835820895, 154.49684210526317, 'entropy = 0.0\\nsamples = 44\\nvalue = [0, 44]'),\n",
       " Text(303.88097014925376, 188.82947368421054, 'X[3] <= 2.5\\nentropy = 1.0\\nsamples = 98\\nvalue = [50, 48]'),\n",
       " Text(301.3824626865672, 177.38526315789474, 'X[3] <= 0.5\\nentropy = 0.996\\nsamples = 89\\nvalue = [41, 48]'),\n",
       " Text(291.0761194029851, 165.94105263157894, 'X[2] <= 28.25\\nentropy = 0.908\\nsamples = 34\\nvalue = [11, 23]'),\n",
       " Text(288.57761194029854, 154.49684210526317, 'X[2] <= 18.5\\nentropy = 0.824\\nsamples = 31\\nvalue = [8, 23]'),\n",
       " Text(282.3313432835821, 143.05263157894737, 'X[5] <= 1.5\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(279.8328358208955, 131.60842105263157, 'X[2] <= 15.0\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(277.33432835820895, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(282.3313432835821, 120.16421052631578, 'X[4] <= 1.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(279.8328358208955, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(284.8298507462687, 108.72, 'X[5] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(282.3313432835821, 97.27578947368421, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(287.32835820895525, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(284.8298507462687, 131.60842105263157, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(294.8238805970149, 143.05263157894737, 'X[2] <= 24.0\\nentropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(289.8268656716418, 131.60842105263157, 'X[5] <= 0.5\\nentropy = 0.667\\nsamples = 23\\nvalue = [4, 19]'),\n",
       " Text(287.32835820895525, 120.16421052631578, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(292.3253731343284, 120.16421052631578, 'X[7] <= 0.5\\nentropy = 0.764\\nsamples = 18\\nvalue = [4, 14]'),\n",
       " Text(289.8268656716418, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(294.8238805970149, 108.72, 'X[5] <= 1.5\\nentropy = 0.672\\nsamples = 17\\nvalue = [3, 14]'),\n",
       " Text(292.3253731343284, 97.27578947368421, 'X[2] <= 21.5\\nentropy = 0.722\\nsamples = 15\\nvalue = [3, 12]'),\n",
       " Text(289.8268656716418, 85.83157894736843, 'entropy = 0.75\\nsamples = 14\\nvalue = [3, 11]'),\n",
       " Text(294.8238805970149, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(297.3223880597015, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(299.82089552238807, 131.60842105263157, 'X[2] <= 25.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(297.3223880597015, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(302.31940298507465, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(293.57462686567163, 154.49684210526317, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(311.68880597014925, 165.94105263157894, 'X[2] <= 6.5\\nentropy = 0.994\\nsamples = 55\\nvalue = [30, 25]'),\n",
       " Text(304.8179104477612, 154.49684210526317, 'X[3] <= 1.5\\nentropy = 0.863\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(302.31940298507465, 143.05263157894737, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(307.3164179104478, 143.05263157894737, 'X[2] <= 3.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(304.8179104477612, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(309.8149253731344, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(318.55970149253733, 154.49684210526317, 'X[2] <= 14.75\\nentropy = 0.98\\nsamples = 48\\nvalue = [28, 20]'),\n",
       " Text(316.06119402985075, 143.05263157894737, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(321.0582089552239, 143.05263157894737, 'X[3] <= 1.5\\nentropy = 0.994\\nsamples = 44\\nvalue = [24, 20]'),\n",
       " Text(314.81194029850747, 131.60842105263157, 'X[2] <= 26.0\\nentropy = 0.918\\nsamples = 21\\nvalue = [14, 7]'),\n",
       " Text(309.8149253731344, 120.16421052631578, 'X[2] <= 19.0\\nentropy = 0.619\\nsamples = 13\\nvalue = [11, 2]'),\n",
       " Text(307.3164179104478, 108.72, 'X[5] <= 1.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(304.8179104477612, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(309.8149253731344, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(312.3134328358209, 108.72, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(319.8089552238806, 120.16421052631578, 'X[7] <= 0.5\\nentropy = 0.954\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(317.31044776119404, 108.72, 'X[2] <= 28.0\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(314.81194029850747, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(319.8089552238806, 97.27578947368421, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(322.3074626865672, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(327.30447761194034, 131.60842105263157, 'X[2] <= 19.5\\nentropy = 0.988\\nsamples = 23\\nvalue = [10, 13]'),\n",
       " Text(324.80597014925377, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(329.80298507462686, 120.16421052631578, 'X[2] <= 39.0\\nentropy = 0.959\\nsamples = 21\\nvalue = [8, 13]'),\n",
       " Text(327.30447761194034, 108.72, 'X[2] <= 30.5\\nentropy = 0.9\\nsamples = 19\\nvalue = [6, 13]'),\n",
       " Text(324.80597014925377, 97.27578947368421, 'X[2] <= 29.5\\nentropy = 0.937\\nsamples = 17\\nvalue = [6, 11]'),\n",
       " Text(322.3074626865672, 85.83157894736843, 'X[5] <= 0.5\\nentropy = 0.896\\nsamples = 16\\nvalue = [5, 11]'),\n",
       " Text(317.31044776119404, 74.38736842105263, 'X[6] <= 2.5\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(314.81194029850747, 62.943157894736856, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(319.8089552238806, 62.943157894736856, 'X[2] <= 26.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(317.31044776119404, 51.49894736842106, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(322.3074626865672, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(327.30447761194034, 74.38736842105263, 'X[6] <= 2.5\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(324.80597014925377, 62.943157894736856, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(329.80298507462686, 62.943157894736856, 'X[2] <= 22.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(327.30447761194034, 51.49894736842106, 'entropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(332.30149253731344, 51.49894736842106, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(327.30447761194034, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(329.80298507462686, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(332.30149253731344, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(306.37947761194033, 177.38526315789474, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAADnCAYAAAC5W1UtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29e3gc2Vnn/zltSd0ty7Zsy5ZkW7bGMx5PmHjGmZsnY8d2uOQ2CQR2ILCw4RI2yQZICJCQ3wILm2d/BEggy/7YH2EhEAghkA2be0KuY8/YCTNhiCeeIR5HlmVZsqUZSZZljd2WJZ/9o6ra1aVzqk91VVe1Wuf7PPXYXXrrvO+5vX361Hnfr5BSYmFhYWGRLnJZG2BhYWGxHGGdr4WFhUUGsM7XwsLCIgNY52thYWGRAazztbCwsMgA1vlaWFhYZADrfC0sLCwygHW+FhYWFhnAOl8LCwWKxeKYEEKaXMVicSxrey2WHoSNcLOwWAwhhJRScvToUdauXUtnZycLCwu0tbUxNDRET08P27Zt82SRUoqMTbZYYrDO18JCAc/5jo+P09XVxfPPP8/q1at1stb5WkRGS9YGWFhkCSFEG7ANuMl3bQd45JFH8C9OOjs7kVJy9epVADZu3MhNN93klfM7wGnfdU5KuZBaRSyWHOzK16KpIYTIAb0sdq7e/7uBUSod52ngI1JKjhw5wvj4OBs2bABg586dzM/PMzAwQKFQYM+ePQghAP5bQMc6YNhX3mCg/ClpJ9+yhnW+FkseQoi1qB3rTTir2otUOj6/IzwrpZxXlGnsG1XbDkKIItCP3unnWOyQvc9DUsrLpvW3WJqwztei4SGEKOA4sqBj9T7n0K8wh6SUz9egUw4NDTEyMkJHRwddXV2MjIxQKpXo7+9nbGyM+fl59u7dW9Oer/uFoavPNmBaU59BYET1hWGxtGCdr0XmEEKsALZQ6Yj8zmgdcJbFjshzRon/hC8Wi2OlUqnbRLZQKIxfuXKlJyndga0SlYPeSOVWSbBdnrVbGo0P63wt6g7hbIp2od8a6AMm0P8Mty+vfBBC5IGtqNtzO1BA/SV1GjgtpbyUgdkWAVjna5EIhBArUTtW77qGft/1jJSylIHZTQkhxGr0e803AZfRb2kMSynnMjB72cE6XwsjCCFaqVxtBSf1KmAI9dbAaSnldPpWWwTh/grZiPpLcjuwCRhHv6VxXkp5PX3Lmw/W+S5RmO5Jmu5HupOyB/1qaRNwDv3qddxOyqUPIUQLzjaQbhysAc6g2daQUl4w0ZPlnnqjwDrfJQrTo1D+N/FCiA3AAeA6i1c824BZ9CueYSnlteRrYrGU4G4v9aP/BXQd9fhZDfxvb+8+7lG+ZoB1vksU3uA9dOgQxWKRvr4+FhYWaGlpYW7O2bLbtm1b0Pn+b+Ah4NOotwZms6mNRTPA/fW0DvWK+WXAG6SUf+nKlsdvW1sb/f39LCws0NHRwcmTJ5dF7gzrfJcohBDy8OHDzMzM0N7eTqlUYvPmzYvCX7dv314xcEWUJYeFRUIIjruw8Xvx4kVyuRzd3d3ceuut1vlaZAchRC9wF/Ai99+7gG2m2w7Ao8C3gH91r+/YQ/oWWcJuO1jn21Bwf7ZtY7GjbeWG4/Sc6MlHH31UmXfg1KlT5PN5f96B7/OVdRfOC5WnqHTIT9njXhZpwXO+utwZExMTtLe3s2PHjqZ1vjarWUZwo5h2sNjRXuGGQ/xz99+zwWWCEIKFhQXuueeecgjs/Pw8g4ODtLa20t/fz+HDhwGQUn4N+Jrv2Q7gTlffi4FfAHYIIU5S6ZCftPvAFklCCHE78AcAhw8fpr+/HyFEOYR7aGiIrVu3IoRgamqK0dFR77kHpJRfz9L2pGFXvinAPSP7Aiod7Z04UV3+Fe23pJRGrAimR3Xy+fyzJnJu/oQXUrlCvh0nM5ffIX/L9DiRhYUHd+vs3cAPAb9bKBTeFeGo2cVSqTQDfBN4l5Tyu3U0NTVY55swXCe2i8rVrOfEgo62oZ2Y+6VxG5UOeTfwHJUO+V+llONZ2WnRuHB/Zb0D+EXgg8B7ahn3bpa4twG/Bvwd8G4p5USStqYN63xjwB1Yu6l0tDuAk/icLHCsWX6++7ZL/HX2b5f4nfKi7RKL5QH3TPnPAG/H2fL6DSnlmYTK/S3gJ4D/CXxYSnkqbrlZwDpfQ7gpAIMOx3tx5Xc6y+7Fle9Fob997sZ5pxB8UXjKRsI1P4QQ38b5kt4npXyiDuXvAA4B7VLKtUmXnwas81VACNFNpZO9C1gPHKNyZXfCRn3p4e7zBb+w1uK0o98pn7BH35oLbpgy9exX91fYiqU6B5vK+daS78B1tL+Bk7zacxB5Fv+EHrArtvgQQqzHcch+p7wFOI7Tzs8C35VSfsR7Juk8FhbRsVT6wMTOrG300FTO10/3XSgU6O3tLYfcnjx5EiEE+/fvD4bc/jLwfhwOLs/RDtu9yvTgpkC8E8chvxlolVLu8P1d2a8A586dK4eiNut50EaAvw9aWlrK4ezBcOCs+0AIIY8cOdLQNpZtbSYfY0r33SiNb2EG26/ZY6n0gRBCTk1NUSgUuHbtWkPa6KHpgix0dN9CCKanp+npyfzXhkUN0PXrxYsXWbduHW1tbRlatzyg6wMvl0ijzK3jx48vsrNQKDA9Pc3u3bsztKwSuawNSBr79+9nxYoVTExMIITg4sWL9Pb20tXVRS6XY2ZmJmsTLSLAPWVCLpcr96kQgp6eHjZs2EBXVxdzc3Ps3Lkza1ObHro+KBQKAOUsZFlDZacXAZrLNY7La8ptBwO5hvjZYaGHEGIzzhnRnwXWRUgi9MfAH0kph+tq4DLDUplbJnZmbaOHxvkaSACFQmHc+7YLu/L5/HNZ22qhhhDiNiHEB3FOP6wAXtTa2jpl0q+FQuE5YB44JoT4azePgEUCaG1tnTbsg0wjHU3GStY2emgq53vlypUeKaVwv9X6cMJgfwK47N2XUoqrV6/a36gNBiHE/UKITwCP4NDU7JBSvl1KOTw3N7fe3384K2ERvHflypWNUspfA24GngG+KoT4tBBib3Y1W/oQQnRfu3ZtJfC7qj7AYaYeB/456yNc3ljBCfFfAH4A+LfAOGmIzemm2nbwQwjxYeB1Ukr7JqZB4UbGvQL4dRxqmvcBfymlvJxQ+UWcENdfA84Dvwd83p7XjgYhRD/wt8D366I3hRA/BbxcSvkfUjStKoQQa3DP8Espv5W1PX40s/PdBWyXUn4qa1ssKiGEaAdei+N0BfD7wMfqFankRlv9O+BdOLmRP4STE6Ahfn5a1BdCiLcDf9JokXBN63wtGhNuQMVFnGCW3wT+Ka2AFnel/QPA54CjUsqDaei1sFChqfZ8/SgWi2NCCFntKhaLRvlzLfQwaWuvnaWUM8ArgfullF9IM5JQOvgS0OZ3vKZjpRnHS5S+y6K8pHQ2Yt81zcpXFdO9FI7GNAOW0vEeFUyPUbmyDVuPWpB032UxFnQ6+/v7OXNGn8Uy6xwPTRPhViqVug8dOlT+fPDgQYBF1OptbW0MDQ1VUFNbxIcJBXijI1iHlpYW5ubmgMYJIKgHjh49yooVK9i6dWu57wYGBrh+/Tp79uypqcxDhw6xatWqch4O/3ioF4Jz/cyZM/h9gj8ib/fu3RQKBSMmjXqhaZwvwIEDByo+P/LII8zOznL9+nWOHTtWpqYuFAqMjY1x/bp96Z0UZmdnaW9vL7fz5OQkAENDQ9kaZghvrPjr4IUvFwoFcrkcfX19WZtZF0xPT1MsFjl27BgrV66ks7OT1tZWrl69yne+853I5fnn3fj4eHk8dHZ2MjZWn1/+qrkOi31CI6Fpth2EENLP5nvgwAG77ZASluq2g3Dywd4L/HOUbQecPeOGenNeK5p520EIgY7he2xsjHvuuSfTMdlUK9++vr4yEyoQSktdKpXKP6mEEH1SyrOZGd4E0LX18PAw9957b8bW3YAQog14Kc5Rtx/COQMKhNeho6ODXbt2eaJjQojPAZ8EviilfD7VSiQMXb3Hxsa48847Eyvv3LlzdUtso9IJlT6hq6uLEydOkM/nG+JXTFM4XyGEKBQKF/r7+yvoRIINf+7cOebm5ujp6WFiYqJMSw08KYT4LPBeKeXx1CvQBFDR2A8MDAAwPp7tcVr3eNsrcRzuK4Dv4DjOl0opnxFCSBWN+cTEBBMTE9x2222cOHHCP17uBH4QJ/fwh4QQh9zyPiOlXHKh67q+W7VqFUePHk2kvOHhYXK5HI8//ngdarB4ro+MjLB161b6+/u1z2QeZiylXLIXzpfHv8dhnHgK+Gmcn4QUCoUxQFa7XLm1wP+DEwX1eeAg7paMvapfJm1dKBTGUh4bvcCbgC8AM26/vhHorcV+XT2ATncMfgzn/PIjwK8AN2fdL1n0XdpjAWgpFAqXa+m7rK/MDaixwVcCbwWGgMPAq4FcAuUW3An6DPA48BAOR1TmdV4KF/AjwAWchDg/n4H+nThRc99w7fgo8GPA6pT0F4AHgb/AyXXwbeDdOFRJDf1l7vbZNM6WzOuA9THLa3G/jF4C/DhuZro62P0W17luDJF5F84x78zb2X8tqRduQoiNwC8C/wnH6b5XSvlYHfSswPlZ+U6cpCHvA/5GSnklaV3NBCHEm4G3SSlfkJI+74XZa91rNfApnC2AQ1LKuTTs0Ni2ArjfteuHgTbXrk8Cj8oGe2Hn7oVPALdJKc8lUF4Bh49vh6xjGLcbtbhSSjlbRa6jmkzaWBLO103s8XWclcXHgD+UUn43Bb0C2IuzmtqD801+q1wKjdak0Lww85zav8gGTJrjjqPv4caXxHacEOemeGFnUSOyWG5H2Y91/dwDOC9JtmT1EwF4OXACKEapR6PtMzVIvy5E7P8C8Hc42wgXcL6I3wnszLrONY6lPuAXgC/j7Ed/2q1feT866hxJq//S3P/Nwp4052wmK1/TcM5GPBvqx1I931ovROxXUzkhhNiPs830VuDjUsrzsY1tEAiHJulVOJnW3iql/FP3fupzpNHO/GZhT9Qy4yDTo2ZBKnAvBBGoOawxbTRDHWqFKp8G6NvEH2oclCkUCgwMDJDL5Ra1m5TyEZzUk00HKeUF4CPuVYFgGwGcO3djOzbO+IrSdxMTE0xNTYXqizoWTO1XPf/tb3+7zBtXC1Rjb3BwMPVQ+ExXvo1OQ10NYgnRVNcDQggZzKdh2q/V2s2Ta9a2qwaTseXK1dRG3tlm//w/ePAgY2NjNc3JpMvzyozzvKq8RvI7ma18w2io5+bm2Lp1a1amRYKKptpfj2bHihUrKiKLwije4Qa9eFi7Aaxfvz6tKjQsqo2tLVu2xCo/l8tV9B3AiRMnlPra29v9EX6xyisWi4yNjYUGQFSzZ25uju7u6HlxwvxOqVSit7c3cpm1IjPnG+yonp6ecujvwsJCw2eREkK8APT1OHv2LG1tbZ5si5RyPjtr64d9+/ZVfN6/f39FqOfFixfZuXMnGzZsoFQqcfPNNwPqdiuVSoyMjPDAAw94ORSWNXRt6c2TuHMk2HdQ+WXq13fq1KnyF2MS5bW3txstsHTPDwwMcMstt5hX1kVYm46MjLBjx47IZdYK+8ItIoQQd+AwMBzAPdhdRR7gFPAeHOqaplkOt7W1TV67dm2d/149XrjVbuHSRb3niKrvoHr/6fTp9nztCzc9MmGyMKV4zzz22gchxN1CiE8CX8SJfrs5Ak31z+FE+XxXCPGfhBD5LOuSFIKswoVC4VnDfr2+1Po/bdR7jqgYoePQrvuZw72rtbX1Qhz7k6aBbzi/k8Z5trALJ6fCV4H/DPyZ7/7arG1z7XgxTl6AEZyjTsUQ2bVVPr8Y53D9CPA2oD3r+tWx3f4E5yzu/wD+i65PgQ/gMOP+f8BvNVr/N8KFE5jxb8BP4nDe1aWNcNidJZD3lw/8knu/phBp4EXAWeD7gSej2o6zSBwD7gEu+eyKXH8cIlWJG+7sK+uq64dSG3eZDyxfo/w6DRR/jbOt8BWc/BFv9gZkQmXfDXwCJ5HPO4COrOtbh/aTwG8Df2PSr64Dbpj+b8QL2Oe2a6FO5W8E7lDcF8D3JlD+Jtf+7THKkMAfxHh+BXCL4v5aoDvN/myY8GLhxML/gJTynzK0IYfjDF8FbAZ+F2eftl6U5ncAv4ETLvtl4L9KKU/WQ1faEEK8AufLqw2HLPNrVeTbTeSWO4QQD0opP5e1HbVCCPEqKeXnYzy/D3haOuejlzQaxvk2AoQQP4QTb/9zOE43lRMK7smJbwJ/K6V8cxo6LSwsskWqL9walVbaR2v+Kem8LPirtByvq/c7UsoOv+NdqnTYYcii/5ca6tlGcco2fTau/UmM+1psyGK+pbryFYqjHv1V6J0hHsWzSqdCBtlgR5pM7HblMrdddcwon88rz4Wm3f9LDfWcI3HmgumzEK+PdXqqleGvfy31zGK+pe58H3744QpK6a1btxIMS1RQPNdcYU9nGK15IziwILzBEKTghhvx/Xv27GkI24UmtFR17+GHH2b16tX09PSk0v9LDUIIeeTIkQoq96TaSFV2MNdCmPMNPgtw+fJlxsfH2b9/f9n5xrFfN+63bt1ajQa+bLc35/008i0tLeWIU9WcV9WvpaWl7Cemp6cTn2+pR7gFKaVBHyU2MDBAa2trIjpVtOb1orFOCioKbillmYK72moiTahCS1X3vPqMjY2F9n+pVGJ0dJR8vimOREdCkMod9HNkcHCwHElZS9mdnZ3lXymPPvpo5GellKxZs4bHHntMKxdm/8TExKI5rhr3oI92e/rppxfZGqSRl/JGiHupVDKu35o1a5ientY+EwepO9/Ozs6KBgR1WCJQbvSkdfpDFBuBxVSHsFDIzs7Ohsp/oepD1b0o/d/oIeb1wpo1axZ9aSU1Rx588EGOHDnChQsX6OjoqBhT1RYjQbs8BzoyMsJ9992XmP25XI6rV6+yevVqOjo6yvlAopShmvPBEHfT+g0MDPDAAw8on4mDzPd8hRAMDQ2VmU67urrKcdtDQ0Ps3bs31lLf7vnWH8LNbtbf31/ux927d6O6p+r/oJw3BjyK7y1btmRex7SgmyOqNpqcnGTDhg0MDg6yb98+o22HLPZ8dfYPDw+Tz+e5cuVK2X6dHpWfGBwcpLW1ddEYWSp7vqmvfD2Kbq8R+/r66K+S3ShuuN+ZM2cqOs2jlR4cHGTv3r1xiq4LhDuKg23V1dXFuXPn6OnpYWZmho6OjqxNBZz+OXjw4KIXbgcPHlwkG+yLTZs2KeWC5Sdpb6Ojnm2kGlPe1kW1LGm6Zzs6OpiZmdHK9fX1RbJfpae3tzfUTwTrryrDo6/X1VP1jOcrxsbGWLduUSqMeKhX9IbqyoJ2Z6lR/QBF4KOFQmGumt2AzOfz11BE7DTitdT6IqM2eq5ebRSn/U2fTYM6KIkygs9nQTGUyQDDoZOexzlnvC8lnR/CoYRvBfZkUW8DG4XbyV8mJIdE4Jm3u8+k0o4J1fONODH6YinZnVLb/CAOV2BO8bf3Ap9OQMcvAC/wff5FDPnwcCIW54D9wH1owu6BvCu3F4dz74sR7GvBCb8v+u61Ah8HVkUo5++B464t90Z4bhT4faAf2Fqvvs4qn+81bjDNHklJ5xlgVjqhwonTzSeIdwD/vzSkqZdSvl8I8SzwZH3NShTTwBHpjPS0+n9JQEr5aRxCTdXf3pGQjv8Z+PwnER6/DgwCx2V4iO914DTwFE4mQONz2tIJcPrhwL1rwEMR7AQnL8s5KeVVnAhSU5wEHpZSDkXUFwk2vNjCwsIiA2SSzzeLUL4sQ1vT1L0UQnibMXTaFGmE30YN860mW0sorknfpaE3qo4k61cNy4bJIs4xm6WkO8t6miKL/m8UxO0f0+fBnEWiWplBe5IaY2nojaqjVj21IJU933rRSkfV5+ns6upi1apVLCws0NbWxtDQUPkgd71w9OhRWlpaFoU7SimrHrWrRZcpLXsaUPWHqu+HhoaYm5vLxMY0cfToUYQQ2nB30zL848lfRlDOZLzrynvoIWebVQghw+T37dvH8PBwRZmFQkFW433TzYsw+eC4OX36NLOzs7z+9a/X2up/Bigf2czn84vkq9mVVPBPKitfISpj/6NQjNfy7RLUZ6qznivftCjm09QVxaYgxfxypY4XIh4durcqqzaOAePxHmaTEEKZoyMor5MLy+lw//33h1LLq1ax1eSD+R92795dVUfSlPemSO20QzC2W0fhLIRgeno69kpUlVegms56QkUDXigUmJ6eZvfu3XXX5Q34rBCkmK9mY71/iWQJHR16Lpejq6ur6vNh9Of+VaNOrlgscvny5VCbvLEJZpTwOjldTodLly6F6tXNCR0VvVefYP4HEx2mlPdJ08un5nyDcdm6ThkbG+OBBx6InVBHFQcelsBn//79sfRVg053qVRKJHmQia5gDH6aMO3/UqnE9u3by6u3ZoQuQczY2FjVKDMIz/kxPj5uJDc7OxtqU09PTzmC0oQSXieny8dQTe/x48eN5L36PPvss8a2ejqeeeYZ42c8PRMTEzVR1quQyrZDTIrxyLOwHjTWcbDcX7il3f+NjKX2wq2np6fCoXsIyqvkdDmdw8pR2ef7HFp3U1v9KBQKRnmnq9lWC1JZ+c7Nza33/i+EEIVCYVY4nF2hqDWmX5VUulgsjgshNtZDXzW4lNXKF4BJ605Tlyn8/Q9mfQHNmdMhbv9Eed5UzqVo1yYuCCQqX9va2joQJg+Qz+ef9RZAQoi1XkCG//9tbW1TQoi11ezzUM3OWmwtFArjUsoKf1HNLpVtNUHWKXROdwGTOFEvWpp1nGiYL+OEJ7YkqPsYMOrXyQ1G1e9Loe4dwBOuzhkCFN0J6zoC/L2vnqeB36mHrph2fgT4ZZzw7zeqxkMzXkA78DwOY/C3cRmJo9QbJ2z3lcCXgJfqngf+GXgF8BngLSFyjwEvBz4PvDnMHuD7gMs4C7i1wNuAc7X0Gw5z9U+49XhDFb2vdNtthav3HTi09Fq9OGHsx3BCor8G/HS1tnbb7KRfDnga+Jekxmbq53yFEF8E3imlDA2HFUL0AB/DYTRO5E2REKIVmJeBSgsh2qSU+vMtCUM4LMkLwA9LKT+Zlt5GhHvM59ellH+QtS1pQgjxeuCvcXI4RJ6EQog8UAJeLKX85xC5AnAFJw/DXwLrpJSLEuAKIYo4zvQe1641UspUk10LIU4CrVLKmxIudw1OSPtO4J+ABSnljirPKPc4qh6KjmJX2s7XwoEQ4mZgMKmOXKpYru3gfgH3SykHY5Rxi5RywFTO3errlFKeiyNXLwghOoAOKWXikY2+uq0C2qWUmW9pWedrYWFhkQESy+2QNeW1W/6CoVxdYtXTao9adNQS454GlkIuinqh3nkekmi3pHNJpC2XJMV80jlJElv5ClG/I04mZfvKN5VLPFY9IK8sMwoFdq06AjLIGuL364FGOwKYJuLW3fR51fhSHfkyvWdqYxw53ZxIsrw4dfPGXkQ/VHW8Jup8H374YXp7e5Vx5HEo2r1KHzp0SEkHLaWTH0EIsYi2uqOjg4GBAa5cuVIOpFA53yClvSmldpjNKqrtKBTYtejI5XKMjIxw9erVMp2353y/8Y1vlOUKhQLDw8M8//zzFXKm9asFQqjDvnVtH6xDPW2rN8LqbkJxrnv+yJEjzM/Ps2PHDi1NuyrMN8o9nY3+eQdgMv89uSAtvIleXXkmVPVhdTMde6r55tHLFwqFck4S0/Ga6Dnf2dlZRkdHKZVKZbpmgKGhodjUy346aT8ddLFYZGxsrDxgVfTPra2tXL58mePHj2vzCASpqj16+bm5ubITjgqVLaCPnjl9+nQiOjy69SAV+OXLlyvkOjo6mJ+fTzXsOIxOPtj23d3dnD17NjXb6o2wugfH9Ozs7KIELqrnTWja495T2eiFMvvDmVXzv1AoMDY2xrVr1xaV56eFN9ULMDY2Ri53Y8c0Thvoxp4QQjnvdfTyV69e5fDhw5FCjxN1vjqK9pGREW699dZYZYeFSnZ0dJTL11Fjb9iwgcnJSW1GIp3tExMT7NgReipFCxUVNVQPuYyrwwtVvfvuuytk29raKtrFC7Os9culFpjQyfvDbXU030sRUes+Pz9f9XlTmvY493Q2jo+PV8zrsDnk78egXFS9g4ODFU4uThtEnfe6+eaR8ba0mLtUu+drWH5Se75CQYE9PDzM2rVrWbVqVSSa9KW25yuEmmJ+Oez5CiFksN/dvq72XLn/TNpOiMU07bt37451r957vjqbky4v7thr6D3f4OAaGBjglltuYWBggAMHDsRyvsGG6+rqYmpqivn5eTZu3MjmzZuVje7RW2/YsIFVq1aV5YLOV/WcRxt98uRJLyVlJOerKvPee+/l/Pnz2ueivnBT6RgYGCjf27dvX3nyBvtnZmYGIURkp18rdC+NgnadOnWKHTt2MDIywsaNG+nv71/yzte07iMjI/T09DA0NFQxZ3TPB/v/Na95zaKtmrgv3FRjLLhgUNXFG1+Tk5Ps3bu37CxNbFaVNzQ0xPr16xkfHy+3TZw20OnYsmXLovYHtY+7dOkSxWKRs2fPctNNNyn9ixYygTA5oD2fz18nQ8prt/wFQ7nItNFRbU+DJj2KjmqyWVG2L1c6eWBb3DlTre3y+fx4Wv3TqHJhbRB17CVNL5/UQOoBTgHrNX//GPBfE9K1BijixIOfD5G7BvwS8Hc4DKbVyt0H/Gzg3m3Ar8S093uB7b7PLwFuTaItAnrW4lBkfxo4rZEROKyyPwV8FieyLFE7Ytj/DuCKN56ytieF+j6Ak+OkVfP3w8DPGJb1Dzj5Dbw8JYnTnbtjpwfY5urYVEWu35VT9qU7Tgdd+e4QvZ8BBgzkPufK3erq7TKs1xrgR3yfV/s/a55Z7eq4A+jG3UGIeiXywk064YDaNyNSyh9LQo9b1kUAIcQHcWLRdfisez2Nk8SmWrlHCNCYSylPACfUT5hBSvm1wOdHdbIx9XhZoz6Ak0RFJSOFEJ8HvgJcAF5WD1tqxDHgr6A8npoaUsqvAy8M+fuBCMU9jNN+4zi5CxJnBpCO1xkTQrTgUMEr56bLYZ0AACAASURBVFRA7kvAJU2RXwEOu/Jhob5fBb5mIPdl9zrt/jsbIuu39yLwf3yfZ/yfNbji6nhGxsg7Y8OLLSwsLLKAyfI4iX25WvZLkt4PrMceTz32sdLoj0a7kt5Py/pKa87Uqz1M3hHEtS8NHVHbMs25bLTyTeIoVi3HNJI+Aha1PFN5gCTlqtWnnsf6skLSx3iyRlpzpl7tYXI0EeKN5zR0mOqKqi8Ju4z3fFWUzQMDA1y/ft2Y6rsWuvDgM6YU1bqjJcHyVOGB1WyemJhgampqkXwYJXgtcmEI2rV3795Fx2uitEvgOePjbrXChE4+l8sxOzvL9PT0kqSTD6Ntj0I/fvToUYrFIj09Pcq+FkLIav1aS58+8cQTFX1x3333ce5cZZZJVZ8F5cLsq1Y3v5y/LWtpA93cF0JUcDhW06UrDxxKei80uRqMV75xqZSFqE5pHixHpVcIM4pq3b0otOomNvu/BZOk89a1Yz3aJU5+iVrhnVH229VMdPJJzRnVePHOs3vwKNKTyhni6b58+XJFXwT16vrM1D4VrbtKRxJtUI2m3rMbUNpUD3p545Wvjkp5bm6O7u5QqqgyqtGFb9q0qapeiBenHmaDFxduYnOQftuUptuU9rsakmwXP523lxciDUShk0+Ssjst6OYMwPr163WPVUA1XkDNHpxkzhCAxx9/PFQvqPvM1D5Qj+OgjiTaQKXLP7a8HBM6m6LQy4NZ/xo7X12lgvHdYQijbn/JS15SkSxDpxfixamHUdbv3Llzkbwp/XYScmGRb/VulyxgSic/OzvLrbfeWl6ZLBXo5szQ0JDxtoNqvEA6/WoyxuLaZ6JDNS6i6NDp8vpjeHiY/v7+SDaFlRfMZaGFyZtPRywcrkysMoLlqJ7Ztm3boreK+Xze6F7UepjKJy0na+iP7u7uWO3iv9I4UdDa2joZtW987fhWXPLRRr3qOWdUfd3a2ppon5qOsbj2paEj7hxV+ZxE+jfsj97V6EfNqGQ+Xuv/1///1tbWqXroT/uomcpxBS9/WKWqLaq1VT0voBV4Cw7b7UeBW1wqbpPxMYETzXQaJ1IvV297a7lM+iipo2b16NNq9rvjuWqfhdmXhg5ffYzmvmmbR/UlynkQcdLcDTwHdAGfqKVzcaKY/sx7DvgC8FthZQD3A+eBlTiMrV21DipggzvpV7n6XwQMVSsLJ9zzZ4G/8NuvkHsU+BlX7k9D5I4ArwfeD7yshnbsA0ZxQq3X4oSrDtTSJmldOLRVP+7a+UXgrirya3WfcWjAvwE8CbyKGkM861zfO9yx5dGrvwYnpLiWcfsUTkTiB4G7o46XGu0XwHdwQuS/APympl8E8AxwwJ3fu0ztc589iRN2/yHge0J0DOCkAfgbnZyBvn73+f04IdkrNPPzJhwW57s8OY1d2125g25fK8tT2hLR8Pfi0C6nPYj/B06uBoHzrfLjGdgggde5HXepityPAh8BZqrIhcaQN8vlDsiXAf8KPA58b0LlCuC1wL/hfDm+OOu61qn92tzxEvplVQe9RVfvC4HHgAGNXLsr94IadHS4z4bmO8FZLFWVi6DXy4OhzRcRkNtYRa7PlTPKKSGlYZCFB+G88WiRUl6rKpwg/HqFEK1p63dtKOsNs8H7W7W2yqoeWUAIcQV4HngT8H9klEFnVn4Lzq+I38dZYbYmrSNrZD3uhUN1n5NSzofJxdGRlFxWeqPaZ3M7WNQdQojXAl+XUj5bZz3bgJ+WUr67nnosLBJB1OV6kvHY9YznT/slWNb2pVmPpZRbIg1b0+ijRm/zNOoWVUejz7HQla8ue/6RI0doaWlRsop65+WklBw9erRCzs96etNNN5XLCobv7tq1i9HR0QqdUcMnhcs06g9dVDHDqmxQhTDHYQPQ2R7UCzA1NUWpVCozJqvkcrkcp06dIp/PV5UbHR1FSlkTA7MOXtsGdY2MjJRl7r///kR0xUU1W5NoF0+Hf6z7Q8aDY62aXKFQGNfNu7Bw5bj1UM33OONZNf7C6uZvF11Ib1BOx/YMNyIE/X7o/vvv15Yb9EO33377orP3qjm7Z8+emthpQp1vMARUFxIYeAZwnK9JuG2c8EQp9eGTpuGdYB5OqLqnstP02VrtiyOXlPNNS1dcpGFrnLGmk6tHOKtJPeKE7idZtyRCelXh2WvWrDFOOxAnnDrMN3moGuFmEhJYKBSYnp5m9+7d5fthYbR+xAlP9CJKjh8/rrQ9LPzPHxIdJ1RXZafpsyr7Ll68yLp16yoGlkpOCEGpVKoIY0wiBNwUOl25XI6urq5EdcVFWFhpUiHLuj6anp6uiJ7S9TlQIRdnvMRBnNB90/Fn8mxUHblcrkLOQ9AP6co18UOmcn7fFMYMXtX5moTVqSjIdaGiExMT7Nq1K1ROp1cXOuiPyw6z02uQUqlUUzhh0vdU9qko7nX1GBwcpK+vr6pclBBwU+h0DQwMRMrYlQZ0tk5PTyvpwZPUMTMzU5GzRNfnZ8+erchqF2e8xEHS41k1/moNMw7TMT09rWyDYPizrlzTMOko/gr0vgkMth2i0l0nkRNTiMX06h6jaJClN5/P09fXt4h9N07+Tu9nhJ8RNS79dhaU3Cq5pLYd0tIVF2nYWo9csXFpzmuBt81Y7/Fs8qxuDkZpA1W/RCk36IdM5Tx2ZyGE0jeVn6vlhVs1CnJQ0017NMsepblOTpU3tJYXbjpa9e7u7lDKa1P99aDknpmZYXZ2lk2bNmntm5ycZMOGDQwODoZScnvllUolNm7cmBg9vOpLeWRkhK1bt3Ly5En6+/vp7+9vGOerGweFQoEtW7bEbpdq7RFGc97V1VV+yer1ue6llMl4yfKFm8n4M62bKZ384OBgefXvzQW/8zUt19QPqeTuvffeml64JX6kxB41y8Y+e9QsO1vtUTN71KyWPqi5sV1l78IJt50NkRPu9bdUD8v9VU8+qUEB/CFwlRuhyT+okfvvQMmzOa1BC/wpDgtzi2vf91dpS0/upRqZP8dhbm115Q7U2X7v19M14P9Nq91qsPNjwFS9+9fto3Vu2yvDbYFPAc/Vaouro9vVsSPrtg3Y9hVgBNjq2tcX4dmHgWGcvAoS2FylDba7ckoae5+sR/V+F06uiic0cp2u3J04uSq+Gabf/fck8HgtbRWHOv6PcJJorAcGdULSs1SI9wDfDSnv/cCHPfkE8Y/AOSmlFEK8D3hCI/dxnI6nDjaE4e+Bf5NSzgsh3g+oj25QtmteCPHfcRKtqPBR4EnphISGySUCX1v9Bs7kaVT8NU4yn7r2rzvOLuB8qZ7RiP0l8IlabXF1PAt8ACfpSyPhf+Hk8hgB/oxwuvcgPuD+e6bas24bDLn6qkVOzrpyTwK/juOzVJhx5Z4C3onjjLX63f++E8e5R4YNL7awsLDIAIupI2KgWCyOCSFk2FUsFseSfjYt2+ttQxRb0rAjqk1Z2GWKpNs0jbHeiOMgbTRCG9TLhkRXvnGO9WR9fMlEf71tiGJLGnYE9DVM+9SCpNs0jbEO0GjjIG00wlyolw1Ge76mR1DAOYqxatWqyFTv3rPFYlEbt52UrWHH1oI21Er3bWpfGKX2ihUr2Lp1qzaGXAg1XXY9aMQ9BNtH1b9CiPJIjaMrDnTHJIP2g0P3XWsEoH+8q/IG6Poo2L8dHR1MTExw/vz5RTTmQblg7hN/e0O6bR7FN3jw7DN9VtUGd9xxR0UuEX8b1OtYaDW/FnXcGznfUqnUbRrfPTs7y/Xr1xkfH2fz5s0MDw8bx4Z7zx47dozNmzcj5Y0QzbDODNpaLS+ETv8jjzyitAGc84VJIGifzpbp6WmKxSLHjh1j5cqVdHZ2cv78eWNK7iqx5jV5GlX7DA8P10VXXKjaOax/z5zRvRvTw1/e+Pg4Z8+eXdSXuvGn6l/vLbg/XF4lNzo62jBtbjLfdPaZzlVVG4yMjITSxMfJUVGrXwvYULUPjE87mMZ3v/rVr0702VpQLS+ETr9/xVFPBG1RhUA++OCDVZ8No+ROmkbcs9PEpmo5N9KCqp2ThKo8Xfhp0BZd/wZhOg6S6N9aEWX8BXMdmMzVqG0A8XJU1OrXvBQKU1NTRu1m7HwXFha45557ypEduntBJxLnWT8V8x133GFqKn19fQghyhEowXtR9Q8PD3PvvffS0hLnZJ7aPnCyPPX391fcU9liUjfdvcHBQdauXcuqVasi2yuEWBHFphMnTpTDvrNEsJ2r9W9UmIx1zxkEbQmzZ3JysqqeJPs3LkzHX6FQYOPGjZGeBfNx5+kAc5+TpF/zxpJnQzUYeZNCoTB+8ODBRXszBw8eXCQbNKivr2+RnO7ZYGOeOXOGvr4+Zmdnyy8gTGzt7+9fZKs/kY6p7V6imFtuuYXHHnuMvXv3GtkQxb4otmzatKmiHqq66e4FbTC1VwhxAIdDT2lTb29vYrqShGoc6Pq3UCgwPh7dTJOxDur+CH7hemHGXqhwmNzmzZsbps1N5pvqmSjPms4FfxkmPsf0Hiz2Tb29vUo5XznVWVtqiczQXUs5fLKeoc5ptmNSF7AN+AecA+8/FqF9pnAILb+EyzDbCFfSbdqI4bTNeDVCG9TLhroYC/wATtRJG05o700Rns3hhAQX3Gf70+5wHJbil+NEKX0iq4EH/DHwVt/nD+JwlNVTZzvwO8Ak8NtAew1ltAJvBZ5z69AwdPY44dc/5/v8UeCHY5RX0Sc4YczKEHbFs8L9cns58EngAyFywzgM0O8Ebs66HTPotxXAGLAXJ4T5vRnYsNGdGy8CJnCIWmsvr05G/jYw4f7/GvDvaihDAPPAazPs8PcBI1npT7murTjsv2dwVrxbEyhzA07I6LjrhFdnXc9GuriRf+N7cMLbn9TIedTxO7O2OcO2Wum2wRacMPGvZ2jLBteW9XHKseHFFgAIIV6Hk2fi+6WUX0247N3At4DflpZZ2MICsLkdLCwsLDJBorkdoqIR8gVkHTtezzj/rOuWRL3rWXZWcvWoU7PneEgbacyd2CtfXRinSYhhqVTqltKM2ln1fBIhlEIsphZXhQ7WU7/XBkII+vv7F1GKe0dqTORkgEpJR7UtpSwfYZIZ5AZQtTs4ob5Xr15l//79NdumKrutrY0TJ04ghCiXDYupwHVyXtv7ZVtaWhgeHlb2kb/NvRD1hx56qCIkFqJTs+to5xuFOSQpxAlbTkK/f16aUNrXYkNs5yvEYrppU6p3cAZrNWpn/7Pt7e2sXr06scEmxGLabyEW01ab0kHXoj/YBkEmWr8DqCYXdL6NSvEuhJAqGu4kbDMtG1BSgavkkugj1biKEuIaZmtW/VgvCOFQAHnwfEqVkN7E2kA3L4WojSZehURCtnTMnyZhpybUzn7m49tvv51cLtndEhPaan/oYD6fT1R/sA2C9OYmcl4Comp185frZ8vNAioabilvUKnXo+xiscjY2FhVOY+S3UNY27e3txvJQbwQV5WthUKB6enp6A20BKAKPdbNy0uXLiWuX9WXKrtqDe1OJl6W2qneVYOsFhrmODClra6XDboBNTw8XBFVp/qS89NzqxBGOx8WhZQGwibS/fffH6vssLbyh/jq5DxSRpPy/M48rC8hHjW7rmzdF+9SRxSfUg9EpYmPirrt+ba2tnLt2jXtc/49Xz/6+/uNMkwlveca1YZ66lfIANFzu5qWndW2Q71sS7pNk5JTjasoe75hZTfbtkNbW9vktWvX1vnvVdvzzefzz5VKpY1agQjQjaGenp7QUPRIfqFOh5DXBv+vumcasprP58dVZSdxtba2TlbT79q5yP4krnqGmprWrR5jwKDeU/WyLSvW2lr6KMJcGa8yR57Noh/TunTzL+t5GUd/5o3qM/xzOPkAPgj8ctKNaaC/G7gAvBAnLFakqd+14RAOseJHgTfq2sBto7fgBEX8fFhbAbe7g6UXWAv8kvs5s5Bf4DeB5wkwK/ucTxvwCE4IZy6mrn8BPgR8BvjxkDb9GPBTwGeB14XIfRz4SeDzwI+GyP0j8BPAPwEPhfVRxPrsxsmdcR9wPNh29kp8rF4F/sFrY3fuvCmRvsy6corK/gMwl4He/wUscINiPnJIdIK2fAGY1fzNs+9ncMIsLxmUtybscwb1ex/wF1Vkbsah5c4npPMbgHJ1iJM3QAIPAo8B4xq5FlfuFcA3AeXKnBthwy/DYcs+l2DbPYyzSOhydTRM8qJmvIA1uNuzqs9xrsReuCWIX8FZVaSNPwK+KKWUQoi34CTvyApvAR5Q/cG17+3A3wGHdXKBZy6GfU4bUspfM5A5BdyaoNo3AC/Q6FoQQvwqzir1dIjcvCv3JRzK9p0auWuu3FeAUZKtx28CBSnlhKvjmQTLtgignnPHhhdbWFhYZIBMwosbOew1LWRFZV7vtq9H+Y1SN4vmRFbjK5OVb9bHu+KERCcdvuhHPY8iuTqN5WSNx5bqcYQsztGxOG1aDxZcD6ZjKesw2+WAeh73DENme75BKuYzZ86YhPQmwsqqYmOuJ+uvDkFKbFUbRAk/DaNF9wdUqGjpPf6rPXv2xK5XsG89O7ycDUmUmcvlynkS/DabjKu4TLa13vNHpJmw20I8dmCLaAjOH3/ujFrkqiGzle9nPvMZ2tvbKZVKbN68md27d9d1RRbUr9Llll93/Z4Nn/3sZykWi5RKJVauXMnBgwcX6VfZpLsXbFMpb4Tq9vT0cNtttwEQ1BsMgY0TI6/qW6/sUqlEb28vO3fujLzy1ZUJjvP1ViYm4ypKmyZ5T/H3qm2gGqtpjtPlAOHmp5mZmdGOW4+vTSfnha27c7ixV74qKuYw9uJdu3Ylql/HiKqzoR6x4ypKbBVLquk9VZua6k0SpnbUo0yTcZXVPW8smVKL11J2PcbpcoDpL7IwOc+HmCIz52tChz0wMMCWLVuYnZ1NPJmOCcW3xyh78eLFutCgm9BRR7ln+uWlkzt//jz33HNP4vXyU7TXWn6tdYPkacRV91QU6KoxNjMzQ2tra6S6m1KzZ0Ud3yzQjTF/cqswOX+ODxNk5nyDg6caHTYkR4ldKBTGDx48qHzhliYltwn1eBx664GBAdavX7/oy0tHod7d3c3o6GjsegXtuHDhAsVikbm5uciOp1qZ1eoWp02j3AuOG10f+f5enVqceNTsFuY4fPhwOb+1N8ZOnjzJypUr6e7uDpUbHBykq6traez56k4b+NHsb2yTbgPT8sB5iZOUXj+EEPlCoXCpVCqFetio5TdC3SyaF5mNryxC9nyhej+JE7/fgsNyvCtLezJqAwH8R6CIw9a8PaHyOtzytmnk3oYTpVUgITp6HFpvCWzQ2DUD/GGM8nPAzwPr3fHSHSL3BhyW2WvAxqz72V6NfwF5YBa42/VNSrZtd87MAne5cqtq0Zd1ePEGnLj3eSHEc0APcLzKM00F6fTmnwvndf0FnAQ/gwmUlwOmgY04dPBBrAfOSilLwF/Xqi+g+yiOk9XZtZgqIlr514G/EEK0AJdw6rDoJ7Yr90EhRKsrtw4w+plvsazRAlwHTkspnzCU+9daldnwYgsLC4sMkCl78XJDViHFST2blP0mTLw2pNgiC6Q57uzKN0UkHXobp7xank3K/mrlRAnlNJUzbVOL5Y00Q41T2/NthHwKjYAg/Tg4EWXnzp0rywghKno1rA2C5XV0dHD77bdz/vz5ivJ07RykxoYbIcmm+iYmJpiamooUmvzEE08sCj8GFpVx9OhRurq6WLVqVSh1dzW5KG1qsTyg80nBMb5v374yB1+YXEdHB0NDQ8zNzRnNhdRWvl4In1+fKcV8s6xahFBTmosa6aijlBdsZy+UOQsqeiGEvHz5ck107cG66epRa5taLB+ofNLBgwcJjnEhhDJ3R9y5kOppBx0bqI5h9+mnn07TvFSgov+G2tvAtLzgPdDTnAdp0/1QUdF78qoBqMPjjz9eUY6XcGb37t3l+ybU3aZy/jZ96qmnjO20aG6o2NODY9xUzvtyb29vN5oLqa58VbqWU5IQrw2C4YkHDhyoqQ2EEPLRRx9dFOrY09OzqLxgO3ufdaGSk5OT3HnnnYtWvip9pVKJ0dFRHnjgAeOVb1g5e/fuBcCkbrp61NqmFssHKp8khFg07lRjSSXnDzO+++67q46x1JxvHIr5Ztmb030B1UpHHaU8VTsvxRduqrol2aYWywc6nxQcT7pc40vmhZvGeaydm5u74P1fSnnB+9e7d+XKlQtp2VhvFAqFcSFE1fDEUqn0ApM2iFJesJ2LxeK4EGJjtWdr0Rf2d4DW1tYpIYR6X8NXhqEuYVIP0za1WD5Q+aQI88Jo3IUaUEtYnL0SCWX8MPBGHFrzt7v3aqajxiHUfAMOq+6bopSHQ0H/s8BHgF8IexbYhRNCvM79/FbKAWzR7MehV/8p4BhuiLOqDOATOGGc364i90kcuvaPA/8xbpvaa/lewCuBR4D9wBO++2sDcg/iENkeAL6pk1Nd9pxvRnCPPv088KPAS6WU+RhlCZxwx9dLKT9c47P/HngTcJ+Usr3aM9I3cIKfDfXmgAXgR6SUnzCQe62U8lMhcitwclm8BvgtYKeUsjOKTRYWHoQQT+OEpe8FTgGbpJTnFXLfwaGTfwkwgJNvxCiUPevcDssZr8ShIP9H4IVxCpJSSiHEK4Ev1vjsq3Bo07+IhjY9+EzYZ0O914UQDwJfMJDz7AuTW/DJPQbcFNUmCwsffgy4IqUcFEK8SuV4XTwEXJZSnnbljHOI2JWvhYWFRQawuR2aBEuRit7mb7BYzrAr3xRQC/036I9DmR6RCUII4b35N7LFpLw4elXPmh7rMaWE98MeL7PQwWSO6sZXrePOOt8UoAtjDKMWrxZWrCrv4YcfXkTZPjU1RalUqmD4VYUeq8o7cuQIq1evZv369SwsLNDW1sbQ0BA9PT1s27atXJ5K7+DgIEII9u/fX5bT2dzb21vOybB161atnJ+uWyenalMpncijOKzMFs0NIYQ0CclPMkWC3XZICblcjomJCYQQZWcUvNfT00NHRwft7e3k8+GHH1Tlzc7OcvHiRY4dO8bU1BSTk5NMT08DVKwSV6xYUX7WCz1WlTc9Pc1zzz3HsWPHGBwcZGxsjM7OTsbGxiq+6VV6C4XCojrobB4dHS0/Gyb3/PPPV5VTtemGDRtYs2ZN1C6zWGZQzQv/PXDYi6vJXbx4kd7eXrZs2cLJkye1+uzKNwXowhhNfq7rVr6q8nThjhMTE9xxxx1lokkTW8LKm5qaYteuXeUBqZPz2JB12xMqHaahnDq5sDY1ib6zWJ4wmaO68VXruLNHzVKCx3rqpxsP3uvq6mJmZgYhRFUKcFV5+/btU8pu3rw5si1RyoujV/VsHDlVmw4PD7N27VqljRYWHs6cOVMxboL3QD2+VM8ODw9TKBTYuFEfBGdXvikgrRduhw4dWjQwBgcHuX79OrfccgtbtmyJ9MJNVZ7/y2HLli1aOY+K3pPTvXALPvua17xGma/XRK5am+bz+Wersc9aLE/YF24WNWMpUtFbSniL5Qz7wq1JcOXKlR53X+ndwHPACmCflFJ4VxTn5Cvvd3EYglfh5HTY6S/PJ/d7wJird6+JXu9Z9/mXAJ2ujls0Ov4IGMUJ+5TA9lrqZmHRCLB7vs2HMeBr0qFPP5pAeeeBrwHP4yS20f1UGgO+6ur9elQlUsojbh6Hp3ByTagwCnwFuFhFzsKi4WG3HSwsLCwygN12aDJkFYobRa8JdXzS9llYNBrsyrfJYJLdsR7nXaPorSZrz+NaLAfYPd8lDtWJARU9vT/cN2p5qqM0YVT0fgp3f0hyUM5PWa+ieo+i14M99WCxVGBXvkscwZj0gwcPoqKTDzyjXVmaxLjHpaIXCgp6YUB3HyeO3sKi0WBXvk2AIJW6ik5eSkmxWOTy5cuRylPRzkelor969Spzc3MVOlT03LXo9VPCh8XRW1g0GuzKd4kjuH8alpPh7NmzvOhFLwpdHZrmodDFveuo6MfHx7n77rvLK99aczXY/A0WzQLrfJc42traJq9du1bBBBznhZuqPBXtfBwqepWDN6W7V93zw+75WiwV2KNmSxxzc3Pr/dFkhULhWS+dou4Ko7QOlgesm5ubK/9fdy+KXpc6vuJvfsfryhnp9f71/m8dr8VSgV35NjGEEJ8HPgr8EPBRKeU/CiHWSikv1Fnvl4C/Al4NPCWlfI9KrxDiT4BngAeAJ6WUv5eGfRYWjQDrfJsUQpQp4V8npfxYBnp/EPhV4C4p5eIjF5XPPALcIS3Vu8UygnW+TQwhxHYp5WAGem+WUp4SQrQCPVLKxTkiK+XzwMZqchYWzQTrfC0sLCwygH3h1sRoJMr1RrLFwqIRYFe+TYI4dPJxzsVGYekI2qKjiffDHh2zaFZY59skEIZ08rlcrsxq7NG6x3G+Or0mtqjo3224sMVygQ0vbiLkcrmKqDFwKNevX7/O+Pg4mzdvLjs2IURi4bgqvSa2qOR6enqYn5/n0qVLi6jnLSyaCXbl2ySISifvp3WPu/I1DQs2CSlWlG9XvhZNCbvybSLEoX9PWm+t9O9+qvdVq1YlZqOFRaPBrnybBFHo5IeHh8nn83R3d7Nly5bUXriZ0sT7YV+4WTQrrPNtYiRNJ98stlhYNALsOd8mho9y/Y+BaaDo/unetCnXfbb8GTDp/r9MHW/p3y2WG+ye7/LAN4ArwFXgk8BzGdryqKdfSqnNrmZh0eyw2w4WFhYWGcBuO1ikDksdb2FhV74WGcBSx1tY2D3fpkSU418e6nXSQHfK4Yknnqigtr98+TLT09Ps2bMnaRMsLBoSduXbhDClf08jh4LOlsuXL9dEbW9h0SywK98mRSNRrqtsefzxx8t/7+zspFAoMD09ze7du+tqi4VFo8CufJsQpvkWFH+vy8o3Ss6JyclJ7rzzTrvytWh6WOfbhDClf/ejXnu+KlsgPM+wzCHVJgAAAT1JREFU3XawWA6wzncZwM8I7P1fdS8tW1pbWwdUDtmDDTO2WA6wztciMwgh/gV4D/CjwKiU8lctdbzFcoENsrDIBEKIHHA3cAHoAP4DgHW8FssFduVrkRmEEK1SymtCCAG0SCn1m9IWFk0G63wtLCwsMoDddrCwsLDIANb5WqQCVTKdQqGgTa5jk+xYNDvstoNFKjClmA9Gu1nqeItmhV35WqSGXC7HxMQEQgicd2yL7/X09NDR0UF7e7uljrdoatiVr0UqqCXk2SdjV74WTQebWMciNZhQzHd1dTEzM4MQwlLHWzQ17MrXIhXUkmMYbKixRfPCOl8LCwuLDGBfuFlYWFhkAOt8LSwsLDKAdb4WFhYWGcA6XwsLC4sMYJ2vhYWFRQawztfCwsIiA1jna2FhYZEBrPO1sLCwyAD/Fx7+DY+Z8tVYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(entropy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如您所见，我们的决策树很大，这可能导致过度拟合。为了减少过度拟合，我们可以使用修剪方法。\n",
    "\n",
    "在决策树中，预修剪的一种方法是提前停止。我们可以限制树的最大深度并限制过度拟合。让我们将树限制为8个级别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       161\n",
      "           1       0.76      0.64      0.70       107\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.77      0.75      0.76       268\n",
      "weighted avg       0.77      0.78      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_tree_lim_eight = DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=42)\n",
    "#衡量分类的质量\n",
    "\n",
    "#深度取到8就结束了\n",
    "\n",
    "entropy_tree_lim_eight.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_lim_eight.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "预修剪后，我们可以看到性能有所提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.超参数调整，训练模型，得出各项指标最精确的模型\n",
    "为了提高模型性能，需要做两件事，特征工程和超参数调整。目前已经进行了功能工程，以提高数据质量。现在进行超参数调整。超参数是机器学习算法中的小属性，可用于优化模型。除了反复试验外，没有其他算法可以做到这一点。\n",
    "\n",
    "模型定义界面的几乎所有输入参数都是超参数。\n",
    "\n",
    "现在创建和训练几个带有不同参数值集的模型。选择以下参数，\n",
    "\n",
    "criterion（ 衡量分类的质量）\n",
    "\n",
    "max_depth（表示树的最大深度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87       161\n",
      "           1       0.94      0.62      0.75       107\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.87      0.80      0.81       268\n",
      "weighted avg       0.85      0.83      0.82       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '5']\n",
    "entropy_tree_ent_five = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
    "#衡量分类的质量\n",
    "entropy_tree_ent_five.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_five.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       161\n",
      "           1       0.83      0.59      0.69       107\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.80      0.75      0.76       268\n",
      "weighted avg       0.79      0.79      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '7']\n",
    "entropy_tree_ent_seven = DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=42)\n",
    "entropy_tree_ent_seven.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_seven.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       161\n",
      "           1       0.73      0.67      0.70       107\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.76      0.76      0.76       268\n",
      "weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '12']\n",
    "entropy_tree_ent_twelve = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "entropy_tree_ent_twelve.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_twelve.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87       161\n",
      "           1       0.94      0.62      0.75       107\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.87      0.80      0.81       268\n",
      "weighted avg       0.85      0.83      0.82       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '5']\n",
    "entropy_tree_gini_five = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\n",
    "entropy_tree_gini_five.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_five.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       161\n",
      "           1       0.79      0.66      0.72       107\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.79      0.77      0.78       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '7']\n",
    "entropy_tree_gini_seven = DecisionTreeClassifier(criterion='gini', max_depth=7, random_state=42)\n",
    "entropy_tree_gini_seven.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_seven.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       161\n",
      "           1       0.76      0.64      0.69       107\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.77      0.75      0.76       268\n",
      "weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '8']\n",
    "entropy_tree_gini_eight = DecisionTreeClassifier(criterion='gini', max_depth=8, random_state=42)\n",
    "entropy_tree_gini_eight.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_eight.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       161\n",
      "           1       0.74      0.69      0.71       107\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.77      0.77      0.77       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '12']\n",
    "entropy_tree_gini_twelve = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\n",
    "entropy_tree_gini_twelve.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_twelve.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "从这些结果中，我们可以选择['entropy'，'7']作为验证阶段性能最佳的模型。信息增益和深度为7\n",
    "\n",
    "现在，让我们使用测试数据集来发现我们的模型有多好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       266\n",
      "           1       0.91      0.72      0.81       152\n",
      "\n",
      "    accuracy                           0.87       418\n",
      "   macro avg       0.88      0.84      0.86       418\n",
      "weighted avg       0.88      0.87      0.87       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =  entropy_tree_ent_seven.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task\n",
    "\n",
    "Use your cleaned dataset from last week,\n",
    "- Complete all the features. \n",
    "- Try to figure out which variables are useful and which are not.\n",
    "- Create few models with different feature sets and evaluate them.\n",
    "- Tune the parameters of the models and figure out which values give you the best performance.\n",
    "- Finally, after deciding the best model, use the test set to measure the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
