{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HanLP工具Demo\n",
    "#### 安装：pip install pyhanlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local c:\\users\\yuquanle\\anaconda3\\envs\\nlpcoure\\lib\\site-packages\\pyhanlp\\static\\data-for-1.7.0.zip, ignore http://hanlp.linrunsoft.com/release/data-for-1.7.0.zip\n",
      "Extracting data.zip...\n"
     ]
    }
   ],
   "source": [
    "from pyhanlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.分词和词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 rr\n",
      "爱 v\n",
      "自然语言处理 nz\n",
      "技术 n\n",
      "！ w\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我爱自然语言处理技术！\"\n",
    "s_hanlp = HanLP.segment(sentence)\n",
    "for term in s_hanlp:\n",
    "    print(term.word, term.nature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.依存句法分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t我\t我\tr\tr\t_\t2\t主谓关系\t_\t_\n",
      "2\t爱\t爱\tv\tv\t_\t0\t核心关系\t_\t_\n",
      "3\t自然语言处理\t自然语言处理\tv\tv\t_\t4\t定中关系\t_\t_\n",
      "4\t技术\t技术\tn\tn\t_\t2\t动宾关系\t_\t_\n",
      "5\t！\t！\twp\tw\t_\t2\t标点符号\t_\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_dep = HanLP.parseDependency(sentence)\n",
    "print(s_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.关键词提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = u'''\n",
    "自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。\n",
    "它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。\n",
    "自然语言处理是一门融语言学、计算机科学、数学于一体的科学。\n",
    "因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，\n",
    "所以它与语言学的研究有着密切的联系，但又有重要的区别。\n",
    "自然语言处理并不是一般地研究自然语言，\n",
    "而在于研制能有效地实现自然语言通信的计算机系统，\n",
    "特别是其中的软件系统。因而它是计算机科学的一部分。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "研究\n",
      "自然语言\n",
      "自然语言处理\n"
     ]
    }
   ],
   "source": [
    "doc_keyword = HanLP.extractKeyword(document, 3)\n",
    "for word in doc_keyword:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.摘要抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然语言处理并不是一般地研究自然语言\n",
      "自然语言处理是计算机科学领域与人工智能领域中的一个重要方向\n",
      "它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法\n"
     ]
    }
   ],
   "source": [
    "doc_keysentence = HanLP.extractSummary(document, 3)\n",
    "for key_sentence in doc_keysentence:\n",
    "    print(key_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.感知机词法分析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[上海/ns 华安/nz 工业/n （/w 集团/n ）/w 公司/n]/nt 董事长/n 谭旭光/nr 和/c 秘书/n 胡花蕊/nr 来到/v [美国纽约/ns 现代/ntc 艺术/n 博物馆/n]/ns 参观/v\n"
     ]
    }
   ],
   "source": [
    "PerceptronLexicalAnalyzer = JClass('com.hankcs.hanlp.model.perceptron.PerceptronLexicalAnalyzer')\n",
    "analyzer = PerceptronLexicalAnalyzer()\n",
    "print(analyzer.analyze(\"上海华安工业（集团）公司董事长谭旭光和秘书胡花蕊来到美国纽约现代艺术博物馆参观\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.中国人名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[王国强/nr, 、/w, 高峰/n, 、/w, 汪洋/n, 、/w, 张朝阳/nr, 光着头/l, 、/w, 韩寒/nr, 、/w, 小/a, 四/m]\n"
     ]
    }
   ],
   "source": [
    "NER = HanLP.newSegment().enableNameRecognize(True)\n",
    "p_name = NER.seg('王国强、高峰、汪洋、张朝阳光着头、韩寒、小四')\n",
    "print(p_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.音译人名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[微软/ntc, 的/ude1, 比尔盖茨/nrf, 、/w, Facebook/nx, 的/ude1, 扎克伯格/nrf, 跟/p, 桑德博格/nrf, 、/w, 亚马逊/nrf, 的/ude1, 贝索斯/nrf, 、/w, 苹果/nf, 的/ude1, 库克/nrf, ，/w, 这些/rz, 硅谷/ns, 的/ude1, 科技/n, 人/n]\n"
     ]
    }
   ],
   "source": [
    "sentence = '微软的比尔盖茨、Facebook的扎克伯格跟桑德博格、亚马逊的贝索斯、苹果的库克，这些硅谷的科技人'\n",
    "person_ner = HanLP.newSegment().enableTranslatedNameRecognize(True)\n",
    "p_name = person_ner.seg(sentence)\n",
    "print(p_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.短语提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[计算机科学, 中的重要, 之间自然语言]\n"
     ]
    }
   ],
   "source": [
    "phraseList = HanLP.extractPhrase(document, 3)\n",
    "print(phraseList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.拼音转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chong 2 chong2 chóng\n",
      "zai 3 zai3 zǎi\n",
      "bu 2 bu2 bú\n",
      "shi 4 shi4 shì\n",
      "zhong 4 zhong4 zhòng\n",
      "ren 4 ren4 rèn\n"
     ]
    }
   ],
   "source": [
    "s = '重载不是重任'\n",
    "pinyinList = HanLP.convertToPinyinList(s)\n",
    "for pinyin in pinyinList:\n",
    "    print(pinyin.getPinyinWithoutTone(),pinyin.getTone(), pinyin, pinyin.getPinyinWithToneMark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声母、韵母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch ong\n",
      "z ai\n",
      "b u\n",
      "sh i\n",
      "zh ong\n",
      "r en\n"
     ]
    }
   ],
   "source": [
    "for pinyin in pinyinList:\n",
    "    print(pinyin.getShengmu(), pinyin.getYunmu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.繁简转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我爱自然语言处理技术！\n",
      "我愛自然語言處理技術！\n"
     ]
    }
   ],
   "source": [
    "Jianti = HanLP.convertToSimplifiedChinese(\"我愛自然語言處理技術！\")\n",
    "Fanti = HanLP.convertToTraditionalChinese(\"我爱自然语言处理技术！\")\n",
    "print(Jianti)\n",
    "print(Fanti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
